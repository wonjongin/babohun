import pandas as pd
import numpy as np
import warnings
import os
import json
import subprocess
import multiprocessing
from datetime import datetime

# CUDA í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (GPU ì‚¬ìš© ê°•ì œ)
os.environ['CUDA_VISIBLE_DEVICES'] = '0'
os.environ['XGBOOST_USE_CUDA'] = '1'
os.environ['LIGHTGBM_USE_GPU'] = '1'

# ê²½ê³  ë¬´ì‹œ
warnings.filterwarnings("ignore")

from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV
from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder
from sklearn.feature_selection import SelectKBest, f_classif, VarianceThreshold
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier, GradientBoostingClassifier
from sklearn.metrics import accuracy_score, f1_score, classification_report, top_k_accuracy_score, balanced_accuracy_score, roc_auc_score
from sklearn.preprocessing import label_binarize

from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE
from imblearn.pipeline import Pipeline as ImbPipeline
from imblearn.combine import SMOTEENN

from xgboost import XGBClassifier
from lightgbm import LGBMClassifier

print("ğŸš€ í–¥ìƒëœ í…ŒìŠ¤íŠ¸ìš© ëª¨ë¸ í•™ìŠµ ì‹œì‘!")
print("="*60)

# --------------------------------------------------
# GPU ë° ì‹œìŠ¤í…œ ì •ë³´ í™•ì¸
# --------------------------------------------------
print("ğŸ”§ ì‹œìŠ¤í…œ ì •ë³´ í™•ì¸ ì¤‘...")

# GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
try:
    result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)
    if result.returncode == 0:
        print("âœ… GPU ì‚¬ìš© ê°€ëŠ¥: NVIDIA GPUê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # GPU ìƒì„¸ ì •ë³´ ì¶œë ¥
        gpu_info = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total,driver_version', '--format=csv,noheader'], 
                                capture_output=True, text=True)
        if gpu_info.returncode == 0:
            print(f"ğŸ“Š GPU ì •ë³´: {gpu_info.stdout.strip()}")
        
        # ì´ˆê¸° GPU ì‚¬ìš©ë¥  í™•ì¸
        gpu_util = subprocess.run(['nvidia-smi', '--query-gpu=utilization.gpu', '--format=csv,noheader,nounits'], 
                                capture_output=True, text=True)
        if gpu_util.returncode == 0:
            print(f"ğŸ–¥ï¸ ì´ˆê¸° GPU ì‚¬ìš©ë¥ : {gpu_util.stdout.strip()}%")
            
    else:
        print("âš ï¸ GPU ì‚¬ìš© ë¶ˆê°€: NVIDIA GPUê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
except:
    print("âš ï¸ GPU ì‚¬ìš© ë¶ˆê°€: nvidia-smi ëª…ë ¹ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print("CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")

# CPU ì½”ì–´ ìˆ˜ í™•ì¸
cpu_count = multiprocessing.cpu_count()
print(f"ğŸ”§ CPU ì½”ì–´ ìˆ˜: {cpu_count}ê°œ")
print(f"ğŸ”§ ë©€í‹°ì½”ì–´ í™œìš©: í™œì„±í™”")

# í™˜ê²½ ë³€ìˆ˜ í™•ì¸
print(f"ğŸ”§ CUDA_VISIBLE_DEVICES: {os.environ.get('CUDA_VISIBLE_DEVICES', 'Not set')}")
print(f"ğŸ”§ XGBOOST_USE_CUDA: {os.environ.get('XGBOOST_USE_CUDA', 'Not set')}")
print(f"ğŸ”§ LIGHTGBM_USE_GPU: {os.environ.get('LIGHTGBM_USE_GPU', 'Not set')}")

print()

# --------------------------------------------------
# 1) ë°ì´í„° ì ì¬ ë° ê°€ê³µ (ìƒ˜í”Œë§)
# --------------------------------------------------
print("1/8: ë°ì´í„° ë¡œë“œ ë° ìƒ˜í”Œë§ ì¤‘...")

# ì „ì²´ ë°ì´í„° ë¡œë“œ
df = pd.read_csv("new_merged_data/df_result2_with_ì‹¬í‰ì›.csv", dtype=str)
print(f"  - ì „ì²´ ë°ì´í„° í¬ê¸°: {df.shape}")

# ë°ì´í„° ìƒ˜í”Œë§ (50%ë¡œ ì¦ê°€)
sample_size = int(len(df) * 0.5)
df_sample = df.sample(n=sample_size, random_state=42)
print(f"  - ìƒ˜í”Œë§ í›„ ë°ì´í„° í¬ê¸°: {df_sample.shape}")

age_cols = ["59ì´í•˜", "60-64", "65-69", "70-79", "80-89", "90ì´ìƒ"]

m = df_sample.melt(
    id_vars=["ë…„ë„", "êµ¬ë¶„", "ì§€ì—­", "ìƒë³‘ì½”ë“œ", "ì§„ë£Œê³¼"],
    value_vars=age_cols,
    var_name="age_group",
    value_name="count",
)
m["count"] = pd.to_numeric(m["count"], errors="coerce").fillna(0).astype(int)
m["ëŒ€í‘œì§„ë£Œê³¼"] = m["ì§„ë£Œê³¼"]
train = m[m["ëŒ€í‘œì§„ë£Œê³¼"].notna()]

print(f"  - ìµœì¢… í•™ìŠµ ë°ì´í„° í¬ê¸°: {train.shape}")
print(f"  - í´ë˜ìŠ¤ ìˆ˜: {len(train['ëŒ€í‘œì§„ë£Œê³¼'].unique())}")
print(f"  - í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜:")
for cls, count in train['ëŒ€í‘œì§„ë£Œê³¼'].value_counts().head(10).items():
    print(f"    {cls}: {count}ê°œ")

# ê°•í™”ëœ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ (ì›ë˜ ì½”ë“œì™€ ë™ì¼)
train["year_num"] = train["ë…„ë„"].astype(int) - train["ë…„ë„"].astype(int).min()

age_mapping = {
    "59ì´í•˜": 30, "60-64": 62, "65-69": 67, 
    "70-79": 75, "80-89": 85, "90ì´ìƒ": 95
}
train["age_num"] = train["age_group"].map(age_mapping)

major_cities = ["ì„œìš¸", "ë¶€ì‚°", "ëŒ€êµ¬", "ì¸ì²œ", "ê´‘ì£¼", "ëŒ€ì „"]
train["is_major_city"] = train["ì§€ì—­"].isin(major_cities).astype(int)
train["is_inpatient"] = (train["êµ¬ë¶„"] == "ì…ì›").astype(int)
train["disease_group"] = train["ìƒë³‘ì½”ë“œ"].str[:3]

# ì¶”ê°€ í”¼ì²˜ (ì›ë˜ ì½”ë“œì™€ ë™ì¼)
train["year_trend"] = train["year_num"] ** 2
train["age_city_interaction"] = train["age_num"] * train["is_major_city"]
train["age_year_interaction"] = train["age_num"] * train["year_num"]
train["region_age"] = train["ì§€ì—­"] + "_" + train["age_group"]

X = train[["year_num", "age_num", "is_major_city", "is_inpatient", 
           "year_trend", "age_city_interaction", "age_year_interaction",
           "ì§€ì—­", "age_group", "êµ¬ë¶„", "disease_group", "region_age"]]
y = train["ëŒ€í‘œì§„ë£Œê³¼"]
w = train["count"]

# --------------------------------------------------
# 2) í•™ìŠµ / ê²€ì¦ ë¶„ë¦¬
# --------------------------------------------------
print("2/8: ë°ì´í„° ë¶„í•  ì¤‘...")
X_tr, X_te, y_tr, y_te, w_tr, w_te = train_test_split(
    X, y, w, test_size=0.20, stratify=y, random_state=42
)

print(f"  - í•™ìŠµ ë°ì´í„°: {X_tr.shape}")
print(f"  - í…ŒìŠ¤íŠ¸ ë°ì´í„°: {X_te.shape}")

# --------------------------------------------------
# 3) ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
# --------------------------------------------------
print("3/8: ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì„¤ì • ì¤‘...")

num_cols = ["year_num", "age_num", "is_major_city", "is_inpatient", 
            "year_trend", "age_city_interaction", "age_year_interaction"]
cat_cols = ["ì§€ì—­", "age_group", "êµ¬ë¶„", "disease_group", "region_age"]

preprocessor = ColumnTransformer(
    [
        ("ohe", OneHotEncoder(drop="first", sparse_output=False, handle_unknown="ignore"), cat_cols),
        ("scale", StandardScaler(), num_cols),
    ]
)

# --------------------------------------------------
# 4) XGBWrapper í´ë˜ìŠ¤ ì •ì˜
# --------------------------------------------------
class XGBWrapper(XGBClassifier):
    """ë¬¸ìâ†’ìˆ«ì ë¼ë²¨ì„ ë‚´ë¶€ ë³€í™˜í•˜ê³ , ì›ë³¸ ë¼ë²¨ì€ orig_classes_ì— ì €ì¥"""
    def fit(self, X, y, **kwargs):
        self._le = LabelEncoder()
        y_enc = self._le.fit_transform(y)
        super().fit(X, y_enc, **kwargs)
        self.orig_classes_ = self._le.classes_
        return self

    def predict(self, X):
        return self._le.inverse_transform(super().predict(X))

    def predict_proba(self, X):
        return super().predict_proba(X)

# --------------------------------------------------
# 5) íŒŒì´í”„ë¼ì¸ & ê·¸ë¦¬ë“œ ì •ì˜ í•¨ìˆ˜
# --------------------------------------------------
print("4/8: íŒŒì´í”„ë¼ì¸ ë° ê·¸ë¦¬ë“œ ì •ì˜ ì¤‘...")

def make_pipeline(clf, param_grid):
    pipe = ImbPipeline(
        [
            ("prep", preprocessor),
            ("smote", SMOTE(random_state=42)),
            ("variance", VarianceThreshold(threshold=0.01)),
            ("select", SelectKBest(f_classif)),
            ("clf", clf),
        ]
    )
    return pipe, param_grid

# k ê°’ì„ ë™ì ìœ¼ë¡œ ì„¤ì •
preprocessor.fit(X_tr)
n_features_after_prep = len(preprocessor.get_feature_names_out())
max_k = min(n_features_after_prep, 50)  # í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ 50ê°œë¡œ ì œí•œ

# ë©€í‹°ì½”ì–´ í™œìš© ì„¤ì •
n_jobs = max(1, int(cpu_count * 0.75))  # 75% ì½”ì–´ í™œìš©
print(f"  - ë©€í‹°ì½”ì–´ í™œìš©: {n_jobs}ê°œ ì½”ì–´ ì‚¬ìš©")

# ëª¨ë¸ë³„ íŒŒì´í”„ë¼ì¸ ë° ê·¸ë¦¬ë“œ ì •ì˜ (GPU ìµœì í™” í¬í•¨)
pipe_lr, params_lr = make_pipeline(
    LogisticRegression(penalty="l1", solver="saga", max_iter=1000, class_weight="balanced"),
    {
        "select__k": [max_k//4, max_k//2],
        "clf__C": [0.1, 1, 10],
    },
)

pipe_rf, params_rf = make_pipeline(
    RandomForestClassifier(class_weight="balanced", random_state=42, n_jobs=n_jobs),
    {
        "select__k": [max_k//4, max_k//2],
        "clf__n_estimators": [50, 100],
        "clf__max_depth": [10, 20],
    },
)

pipe_xgb, params_xgb = make_pipeline(
    XGBWrapper(
        eval_metric="mlogloss",
        random_state=42,
        tree_method="hist",  # GPU ìµœì í™”
        device="cuda",  # GPU ì‚¬ìš©
        max_bin=256,  # GPU ë©”ëª¨ë¦¬ ìµœì í™”
        single_precision_histogram=True,  # GPU ë©”ëª¨ë¦¬ ì ˆì•½
        enable_categorical=False,  # ì¹´í…Œê³ ë¦¬í˜• ë¹„í™œì„±í™”
        max_leaves=0,  # GPU ìµœì í™”
        grow_policy="lossguide",  # GPU ìµœì í™”
    ),
    {
        "select__k": [max_k//4, max_k//2],
        "clf__n_estimators": [100, 200],
        "clf__max_depth": [3, 6],
        "clf__learning_rate": [0.1, 0.2],
    },
)

pipe_lgb, params_lgb = make_pipeline(
    LGBMClassifier(
        objective="multiclass",
        random_state=42,
        verbose=-1,
        device="gpu",  # GPU ì‚¬ìš©
        gpu_platform_id=0,  # GPU í”Œë«í¼ ID
        gpu_device_id=0,  # GPU ë””ë°”ì´ìŠ¤ ID
        force_col_wise=True,  # GPU ìµœì í™”
        gpu_use_dp=False,  # ë‹¨ì •ë°€ë„ ì‚¬ìš©ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½
        max_bin=255,  # GPU ìµœì í™”
        num_leaves=31,  # ê³ ì •ê°’ìœ¼ë¡œ ê²½ê³  ì œê±°
        min_child_samples=20,  # ê³ ì •ê°’ìœ¼ë¡œ ê²½ê³  ì œê±°
        subsample=1.0,  # ê³ ì •ê°’ìœ¼ë¡œ ê²½ê³  ì œê±°
        colsample_bytree=1.0,  # ê³ ì •ê°’ìœ¼ë¡œ ê²½ê³  ì œê±°
        n_jobs=1,  # GPU ì‚¬ìš©ì‹œ ë‹¨ì¼ ìŠ¤ë ˆë“œ
        deterministic=True,  # ì¬í˜„ì„± ë³´ì¥
        force_row_wise=False,  # GPU ìµœì í™”
    ),
    {
        "select__k": [max_k//4, max_k//2],
        "clf__n_estimators": [100, 200],
        "clf__max_depth": [3, 6],
        "clf__learning_rate": [0.1, 0.2],
    },
)

pipe_gb, params_gb = make_pipeline(
    GradientBoostingClassifier(random_state=42),
    {
        "select__k": [max_k//4, max_k//2],
        "clf__n_estimators": [50, 100],
        "clf__max_depth": [3, 6],
        "clf__learning_rate": [0.1, 0.2],
    },
)

cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)  # í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ 3-fold

# --------------------------------------------------
# 6) ê·¸ë¦¬ë“œ ì„œì¹˜ ì‹¤í–‰
# --------------------------------------------------
print("5/8: ê·¸ë¦¬ë“œ ì„œì¹˜ ì‹¤í–‰ ì¤‘...")

grids = {}
for i, (name, (pipe, params)) in enumerate(zip(
    ["lr", "rf", "xgb", "lgb", "gb"],
    [
        (pipe_lr, params_lr),
        (pipe_rf, params_rf),
        (pipe_xgb, params_xgb),
        (pipe_lgb, params_lgb),
        (pipe_gb, params_gb),
    ],
), 1):
    print(f"  - ëª¨ë¸ {i}/5: {name.upper()} ê·¸ë¦¬ë“œ ì„œì¹˜ ì¤‘...")
    
    # GPU ì‚¬ìš© í™•ì¸ (XGBoost, LightGBMì˜ ê²½ìš°)
    if name in ['xgb', 'lgb']:
        try:
            result = subprocess.run(['nvidia-smi', '--query-gpu=utilization.gpu', '--format=csv,noheader,nounits'], 
                                  capture_output=True, text=True)
            if result.returncode == 0:
                gpu_util = result.stdout.strip()
                print(f"    ğŸ–¥ï¸ í•™ìŠµ ì „ GPU ì‚¬ìš©ë¥ : {gpu_util}%")
        except:
            pass
    
    # ë©€í‹°ì½”ì–´ í™œìš© (CPU ëª¨ë¸ë“¤)
    if name in ['lr', 'rf', 'gb']:
        grid = GridSearchCV(pipe, params, cv=cv, scoring="accuracy", n_jobs=n_jobs, verbose=0)
    else:
        # GPU ëª¨ë¸ë“¤ì€ ë‹¨ì¼ ìŠ¤ë ˆë“œ (GPU ì‚¬ìš©)
        grid = GridSearchCV(pipe, params, cv=cv, scoring="accuracy", n_jobs=1, verbose=0)
    
    grid.fit(X_tr, y_tr)
    grids[name] = grid
    
    # í•™ìŠµ í›„ GPU ì‚¬ìš©ë¥  í™•ì¸
    if name in ['xgb', 'lgb']:
        try:
            result = subprocess.run(['nvidia-smi', '--query-gpu=utilization.gpu', '--format=csv,noheader,nounits'], 
                                  capture_output=True, text=True)
            if result.returncode == 0:
                gpu_util = result.stdout.strip()
                print(f"    ğŸ–¥ï¸ í•™ìŠµ í›„ GPU ì‚¬ìš©ë¥ : {gpu_util}%")
        except:
            pass
    
    print(f"    âœ… {name.upper()} ìµœì  ì ìˆ˜: {grid.best_score_:.4f}")

# --------------------------------------------------
# 7) ì•™ìƒë¸” (Voting & Stacking)
# --------------------------------------------------
print("6/8: ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ ì¤‘...")

# Voting Classifier
print("  - Voting Classifier í•™ìŠµ ì¤‘...")
estimators = [(n, grids[n].best_estimator_) for n in ["lr", "rf", "xgb", "lgb", "gb"]]
voting = VotingClassifier(estimators=estimators, voting="soft")
voting.fit(X_tr, y_tr)

# Stacking Classifier
print("  - Stacking Classifier í•™ìŠµ ì¤‘...")
stack = StackingClassifier(
    estimators=estimators,
    final_estimator=LogisticRegression(max_iter=1000),
    cv=cv,
    n_jobs=n_jobs,  # ë©€í‹°ì½”ì–´ í™œìš©
)
stack.fit(X_tr, y_tr)

# --------------------------------------------------
# 8) í‰ê°€ í•¨ìˆ˜
# --------------------------------------------------
print("7/8: ëª¨ë¸ í‰ê°€ ì¤‘...")

def eval_model(name, model, X, y_true, w):
    y_pred = model.predict(X)
    proba = model.predict_proba(X) if hasattr(model, "predict_proba") else None

    acc = accuracy_score(y_true, y_pred, sample_weight=w)
    macro_f1 = f1_score(y_true, y_pred, average="macro", sample_weight=w)
    
    result = {
        "model": name,
        "accuracy": acc,
        "macro_f1": macro_f1
    }
    
    if proba is not None:
        class_order = getattr(model, "orig_classes_", None)
        if class_order is None:
            class_order = getattr(model, "classes_", None)
        if class_order is None:
            class_order = np.unique(y_true)
        
        top3_acc = top_k_accuracy_score(y_true, proba, k=3, sample_weight=w)
        bal_acc = balanced_accuracy_score(y_true, y_pred, sample_weight=w)
        
        y_bin = label_binarize(y_true, classes=class_order)
        roc_auc = roc_auc_score(y_bin, proba, average="macro", sample_weight=w)
        
        result.update({
            "top3_accuracy": top3_acc,
            "balanced_accuracy": bal_acc,
            "roc_auc": roc_auc
        })
    
    return result

# ëª¨ë“  ëª¨ë¸ í‰ê°€
results = []

# ê¸°ë³¸ ëª¨ë¸ë“¤
for name, grid in grids.items():
    result = eval_model(name.upper(), grid.best_estimator_, X_te, y_te, w_te)
    results.append(result)
    print(f"  âœ… {name.upper()}: ì •í™•ë„={result['accuracy']:.4f}, F1={result['macro_f1']:.4f}")

# ì•™ìƒë¸” ëª¨ë¸ë“¤
voting_result = eval_model("Voting", voting, X_te, y_te, w_te)
results.append(voting_result)
print(f"  âœ… Voting: ì •í™•ë„={voting_result['accuracy']:.4f}, F1={voting_result['macro_f1']:.4f}")

stacking_result = eval_model("Stacking", stack, X_te, y_te, w_te)
results.append(stacking_result)
print(f"  âœ… Stacking: ì •í™•ë„={stacking_result['accuracy']:.4f}, F1={stacking_result['macro_f1']:.4f}")

# --------------------------------------------------
# 9) ìƒ˜í”Œë§ ê¸°ë²• í…ŒìŠ¤íŠ¸
# --------------------------------------------------
print("8/8: ìƒ˜í”Œë§ ê¸°ë²• í…ŒìŠ¤íŠ¸ ì¤‘...")

sampling_methods = {
    'adasyn': ADASYN(random_state=42, n_neighbors=3),
    'borderline_smote': BorderlineSMOTE(random_state=42, k_neighbors=3),
    'smote_enn': SMOTEENN(random_state=42)
}

# ì „ì²˜ë¦¬ ì ìš©
X_tr_preprocessed = preprocessor.fit_transform(X_tr)
X_te_preprocessed = preprocessor.transform(X_te)

for name, sampler in sampling_methods.items():
    try:
        print(f"  - {name.upper()} í…ŒìŠ¤íŠ¸ ì¤‘...")
        
        # ìƒ˜í”Œë§ ì ìš©
        X_resampled, y_resampled = sampler.fit_resample(X_tr_preprocessed, y_tr)
        
        # GPU ìµœì í™”ëœ XGBoost ëª¨ë¸ë¡œ ì„±ëŠ¥ ì¸¡ì •
        simple_model = XGBWrapper(
            n_estimators=100, 
            random_state=42,
            tree_method="hist",
            device="cuda",
            max_bin=256,
            single_precision_histogram=True,
            enable_categorical=False,
            max_leaves=0,
            grow_policy="lossguide",
        )
        simple_model.fit(X_resampled, y_resampled)
        
        result = eval_model(f"{name.upper()}_sampling", simple_model, X_te_preprocessed, y_te, w_te)
        results.append(result)
        print(f"    âœ… {name.upper()}: ì •í™•ë„={result['accuracy']:.4f}, F1={result['macro_f1']:.4f}")
        
    except Exception as e:
        print(f"    âŒ {name.upper()}: ìƒ˜í”Œë§ ì‹¤íŒ¨ - {str(e)}")

# --------------------------------------------------
# 10) ê²°ê³¼ ì •ë¦¬ ë° ì €ì¥
# --------------------------------------------------
print("\nğŸ“Š ê²°ê³¼ ì •ë¦¬ ë° ì €ì¥ ì¤‘...")

# ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ ìƒì„±
results_df = pd.DataFrame(results)
results_df = results_df.sort_values("macro_f1", ascending=False)

print(f"\nğŸ“Š ìµœì¢… ê²°ê³¼ (F1-score ìˆœ):")
print(results_df.to_string(index=False))

# ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì°¾ê¸°
best_model = results_df.iloc[0]
print(f"\nğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model['model']}")
print(f"   - ì •í™•ë„: {best_model['accuracy']:.4f}")
print(f"   - F1-score: {best_model['macro_f1']:.4f}")
if 'top3_accuracy' in best_model:
    print(f"   - Top-3 ì •í™•ë„: {best_model['top3_accuracy']:.4f}")
if 'roc_auc' in best_model:
    print(f"   - ROC-AUC: {best_model['roc_auc']:.4f}")

# ê²°ê³¼ ì €ì¥
test_results_dir = "test_results"
os.makedirs(test_results_dir, exist_ok=True)

# CSV ì €ì¥
results_df.to_csv(f"{test_results_dir}/enhanced_test_results.csv", index=False, encoding='utf-8-sig')

# JSON ë©”íƒ€ë°ì´í„° ì €ì¥
metadata = {
    "timestamp": datetime.now().isoformat(),
    "test_type": "enhanced_test",
    "system_info": {
        "cpu_cores": cpu_count,
        "gpu_available": result.returncode == 0 if 'result' in locals() else False,
        "multicore_utilization": f"{n_jobs}/{cpu_count} cores"
    },
    "data_info": {
        "original_size": len(df),
        "sampled_size": len(df_sample),
        "final_train_size": len(train),
        "test_size": len(X_te),
        "num_classes": len(train['ëŒ€í‘œì§„ë£Œê³¼'].unique()),
        "features": list(X.columns),
        "features_after_preprocessing": n_features_after_prep
    },
    "best_model": {
        "name": best_model['model'],
        "accuracy": best_model['accuracy'],
        "f1_score": best_model['macro_f1']
    },
    "all_results": results,
    "grid_search_info": {
        "cv_folds": 3,
        "models_tested": list(grids.keys()),
        "max_features_selected": max_k,
        "multicore_jobs": n_jobs
    }
}

with open(f"{test_results_dir}/enhanced_test_metadata.json", 'w', encoding='utf-8') as f:
    json.dump(metadata, f, ensure_ascii=False, indent=2)

print(f"\nâœ… í–¥ìƒëœ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
print(f"ğŸ“ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {test_results_dir}/")
print(f"ğŸ“Š ì´ {len(results)}ê°œ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
print(f"â±ï¸ ì˜ˆìƒ ì „ì²´ í•™ìŠµ ì‹œê°„: ì•½ 10-30ë¶„ (í˜„ì¬ í…ŒìŠ¤íŠ¸: ì•½ 3-5ë¶„)")

# ë°©í–¥ì„± ì œì•ˆ
print(f"\nğŸ’¡ ë°©í–¥ì„± ì œì•ˆ:")
if best_model['model'].endswith('_sampling'):
    print(f"  - ìƒ˜í”Œë§ ê¸°ë²•ì´ íš¨ê³¼ì ì…ë‹ˆë‹¤.")
elif best_model['model'] in ['Voting', 'Stacking']:
    print(f"  - ì•™ìƒë¸”ì´ íš¨ê³¼ì ì…ë‹ˆë‹¤.")
elif best_model['model'] in ['XGB', 'LGB']:
    print(f"  - ë¶€ìŠ¤íŒ… ëª¨ë¸ì´ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.")

print(f"  - ì „ì²´ ë°ì´í„°ë¡œ í•™ìŠµí•˜ë©´ ì„±ëŠ¥ì´ ë” í–¥ìƒë  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤.")

print("="*60)
print("ğŸ¯ ì´ì œ ì „ì²´ ë°ì´í„°ë¡œ ë³¸ê²©ì ì¸ í•™ìŠµì„ ì§„í–‰í•˜ì„¸ìš”!")
print("="*60) 