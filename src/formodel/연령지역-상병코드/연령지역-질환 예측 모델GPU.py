import pandas as pd
import numpy as np
import warnings
from sklearn.exceptions import ConvergenceWarning
import subprocess
import os
import multiprocessing

# CUDA í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (GPU ì‚¬ìš© ê°•ì œ)
os.environ['CUDA_VISIBLE_DEVICES'] = '0'
os.environ['XGBOOST_USE_CUDA'] = '1'
os.environ['LIGHTGBM_USE_GPU'] = '1'

from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV
from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder
from sklearn.feature_selection import SelectKBest, f_classif, VarianceThreshold
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import (
    accuracy_score, f1_score, classification_report,
    top_k_accuracy_score, balanced_accuracy_score, roc_auc_score
)
from sklearn.preprocessing import label_binarize

from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE
from imblearn.pipeline import Pipeline as ImbPipeline
from imblearn.combine import SMOTEENN

from xgboost import XGBClassifier
from lightgbm import LGBMClassifier

warnings.filterwarnings("ignore")

# íŠ¹ì • ê²½ê³ ë§Œ ë¬´ì‹œ
warnings.filterwarnings("ignore", category=UserWarning, module="sklearn.preprocessing._encoders")
warnings.filterwarnings("ignore", category=UserWarning, module="sklearn.feature_selection._univariate_selection")
warnings.filterwarnings("ignore", category=RuntimeWarning, module="sklearn.feature_selection._univariate_selection")
warnings.filterwarnings("ignore", category=ConvergenceWarning, module="sklearn.linear_model._sag")

# GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
try:
    result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)
    if result.returncode == 0:
        print("âœ… GPU ì‚¬ìš© ê°€ëŠ¥: NVIDIA GPUê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print("ğŸš€ GPU ê°€ì†ì´ í™œì„±í™”ë˜ì–´ í•™ìŠµ ì†ë„ê°€ í¬ê²Œ í–¥ìƒë©ë‹ˆë‹¤.")
        
        # CUDA ë²„ì „ í™•ì¸
        try:
            cuda_result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True)
            if cuda_result.returncode == 0:
                cuda_version = cuda_result.stdout.split('release ')[1].split(',')[0]
                print(f"ğŸ”§ CUDA ë²„ì „: {cuda_version}")
        except:
            print("âš ï¸ CUDA ë²„ì „ í™•ì¸ ì‹¤íŒ¨")
        
        # GPU ìƒì„¸ ì •ë³´ ì¶œë ¥
        gpu_info = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total,driver_version', '--format=csv,noheader'], 
                                capture_output=True, text=True)
        if gpu_info.returncode == 0:
            print(f"ğŸ“Š GPU ì •ë³´: {gpu_info.stdout.strip()}")
        
        # ì´ˆê¸° GPU ì‚¬ìš©ë¥  í™•ì¸
        gpu_util = subprocess.run(['nvidia-smi', '--query-gpu=utilization.gpu', '--format=csv,noheader,nounits'], 
                                capture_output=True, text=True)
        if gpu_util.returncode == 0:
            print(f"ğŸ–¥ï¸ ì´ˆê¸° GPU ì‚¬ìš©ë¥ : {gpu_util.stdout.strip()}%")
            
        # í™˜ê²½ ë³€ìˆ˜ í™•ì¸
        print(f"ğŸ”§ CUDA_VISIBLE_DEVICES: {os.environ.get('CUDA_VISIBLE_DEVICES', 'Not set')}")
        print(f"ğŸ”§ XGBOOST_USE_CUDA: {os.environ.get('XGBOOST_USE_CUDA', 'Not set')}")
        print(f"ğŸ”§ LIGHTGBM_USE_GPU: {os.environ.get('LIGHTGBM_USE_GPU', 'Not set')}")
            
    else:
        print("âš ï¸ GPU ì‚¬ìš© ë¶ˆê°€: NVIDIA GPUê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
except:
    print("âš ï¸ GPU ì‚¬ìš© ë¶ˆê°€: nvidia-smi ëª…ë ¹ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print("CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")

print()

# CPU ì½”ì–´ ìˆ˜ í™•ì¸
cpu_count = multiprocessing.cpu_count()
print(f"ğŸ”§ ì‹œìŠ¤í…œ ì •ë³´:")
print(f"  - CPU ì½”ì–´ ìˆ˜: {cpu_count}ê°œ")
print(f"  - GPU ì‚¬ìš©: í™œì„±í™”")
print()

# --------------------------------------------------
# 1) ë°ì´í„° ì ì¬ ë° ê°€ê³µ
# --------------------------------------------------
df = pd.read_csv("new_merged_data/df_result2_mapping1.csv", dtype=str)
age_cols = ["59ì´í•˜", "60-64", "65-69", "70-79", "80-89", "90ì´ìƒ"]

m = df.melt(
    id_vars=["ë…„ë„", "êµ¬ë¶„", "ì§€ì—­", "ìƒë³‘ì½”ë“œ", "ì§„ë£Œê³¼"],
    value_vars=age_cols,
    var_name="age_group",
    value_name="count",
)
m["count"] = pd.to_numeric(m["count"], errors="coerce").fillna(0).astype(int)
m["ëŒ€í‘œì§„ë£Œê³¼"] = m["ì§„ë£Œê³¼"]
train = m[m["ëŒ€í‘œì§„ë£Œê³¼"].notna()]

# ê°•í™”ëœ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§
train["year_num"] = train["ë…„ë„"].astype(int) - train["ë…„ë„"].astype(int).min()

# ì—°ë ¹ëŒ€ ìˆ˜ì¹˜í™” (ì¤‘ê°„ê°’ ì‚¬ìš©)
age_mapping = {
    "59ì´í•˜": 30, "60-64": 62, "65-69": 67, 
    "70-79": 75, "80-89": 85, "90ì´ìƒ": 95
}
train["age_num"] = train["age_group"].map(age_mapping)

# ì§€ì—­ë³„ íŠ¹ì„± (ëŒ€ë„ì‹œ vs ì¤‘ì†Œë„ì‹œ)
major_cities = ["ì„œìš¸", "ë¶€ì‚°", "ëŒ€êµ¬", "ì¸ì²œ", "ê´‘ì£¼", "ëŒ€ì „", "ìš¸ì‚°"]
train["is_major_city"] = train["ì§€ì—­"].isin(major_cities).astype(int)

# êµ¬ë¶„ë³„ íŠ¹ì„± (ì…ì› vs ì™¸ë˜)
train["is_inpatient"] = (train["êµ¬ë¶„"] == "ì…ì›").astype(int)

# ìƒë³‘ì½”ë“œ ê¸°ë°˜ í”¼ì²˜ (ì²« 3ìë¦¬ë¡œ ê·¸ë£¹í™”)
train["disease_group"] = train["ìƒë³‘ì½”ë“œ"].str[:3]

# ì—°ë„ë³„ íŠ¸ë Œë“œ
train["year_trend"] = train["year_num"] ** 2

# ë³µí•© í”¼ì²˜
train["age_city_interaction"] = train["age_num"] * train["is_major_city"]
train["age_year_interaction"] = train["age_num"] * train["year_num"]

# ì§€ì—­-ì—°ë ¹ëŒ€ ì¡°í•©
train["region_age"] = train["ì§€ì—­"] + "_" + train["age_group"]

X = train[["year_num", "age_num", "is_major_city", "is_inpatient", 
           "year_trend", "age_city_interaction", "age_year_interaction", 
           "ì§€ì—­", "age_group", "êµ¬ë¶„", "disease_group", "region_age"]]
y = train["ëŒ€í‘œì§„ë£Œê³¼"]
w = train["count"]

# --------------------------------------------------
# 2) í•™ìŠµ / ê²€ì¦ ë¶„ë¦¬
# --------------------------------------------------
X_tr, X_te, y_tr, y_te, w_tr, w_te = train_test_split(
    X, y, w, test_size=0.20, stratify=y, random_state=42
)

# --------------------------------------------------
# 3) ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
# --------------------------------------------------
# ìˆ˜ì¹˜í˜• í”¼ì²˜
num_cols = ["year_num", "age_num", "is_major_city", "is_inpatient", 
            "year_trend", "age_city_interaction", "age_year_interaction"]

# ë²”ì£¼í˜• í”¼ì²˜
cat_cols = ["ì§€ì—­", "age_group", "êµ¬ë¶„", "disease_group", "region_age"]

preprocessor = ColumnTransformer(
    [
        ("ohe", OneHotEncoder(drop="first", sparse_output=False, handle_unknown="ignore"), cat_cols),
        ("scale", StandardScaler(), num_cols),
    ]
)

# --------------------------------------------------
# 4) XGBìš© ë˜í¼ í´ë˜ìŠ¤
# --------------------------------------------------
class XGBWrapper(XGBClassifier):
    """ë¬¸ìâ†’ìˆ«ì ë¼ë²¨ì„ ë‚´ë¶€ ë³€í™˜í•˜ê³ , ì›ë³¸ ë¼ë²¨ì€ orig_classes_ì— ì €ì¥"""
    def fit(self, X, y, **kwargs):
        self._le = LabelEncoder()
        y_enc = self._le.fit_transform(y)
        super().fit(X, y_enc, **kwargs)
        self.orig_classes_ = self._le.classes_
        return self

    def predict(self, X):
        return self._le.inverse_transform(super().predict(X))

    def predict_proba(self, X):
        return super().predict_proba(X)

# --------------------------------------------------
# 5) íŒŒì´í”„ë¼ì¸ & ê·¸ë¦¬ë“œ ì •ì˜ í•¨ìˆ˜
# --------------------------------------------------
def make_pipeline(clf, param_grid):
    pipe = ImbPipeline(
        [
            ("prep", preprocessor),
            ("smote", SMOTE(random_state=42)),
            ("variance", VarianceThreshold(threshold=0.01)),  # ìƒìˆ˜ í”¼ì²˜ ì œê±°
            ("select", SelectKBest(f_classif)),
            ("clf", clf),
        ]
    )
    return pipe, param_grid

# k ê°’ì„ ë™ì ìœ¼ë¡œ ì„¤ì •
# preprocessorë¥¼ ë¨¼ì € fitì‹œì¼œì•¼ í•¨
preprocessor.fit(X_tr)
n_features_after_prep = len(preprocessor.get_feature_names_out())  # ì „ì²˜ë¦¬ í›„ í”¼ì²˜ ìˆ˜
max_k = min(n_features_after_prep, 100)  # ìµœëŒ€ 100ê°œë¡œ í™•ì¥

# Logistic Regression
pipe_lr, params_lr = make_pipeline(
    LogisticRegression(
        penalty="l1", solver="saga", max_iter=5000, class_weight="balanced"
    ),
    {
        "select__k": [max_k//4, max_k//2, max_k],
        "clf__C": [0.001, 0.01, 0.1, 1, 10],
    },
)

# Random Forest
pipe_rf, params_rf = make_pipeline(
    RandomForestClassifier(class_weight="balanced", random_state=42),
    {
        "select__k": [max_k//4, max_k//2, max_k],
        "clf__n_estimators": [100, 200, 300],
        "clf__max_depth": [None, 10, 20, 30],
        "clf__min_samples_split": [2, 5, 10],
    },
)

# XGBoost
pipe_xgb, params_xgb = make_pipeline(
    XGBWrapper(
        eval_metric="mlogloss",
        random_state=42,
        tree_method="hist",  # hist ì‚¬ìš©
        device="cuda",  # ìƒˆë¡œìš´ GPU ì„¤ì • ë°©ì‹
        max_bin=256,  # GPU ë©”ëª¨ë¦¬ ìµœì í™”
        single_precision_histogram=True,  # GPU ë©”ëª¨ë¦¬ ì ˆì•½
        enable_categorical=False,  # ì¹´í…Œê³ ë¦¬í˜• ë¹„í™œì„±í™”
        max_leaves=0,  # GPU ìµœì í™”
        grow_policy="lossguide",  # GPU ìµœì í™”
    ),
    {
        "select__k": [max_k//4, max_k//2, max_k],
        "clf__n_estimators": [200, 400, 600],
        "clf__max_depth": [3, 6, 9],
        "clf__learning_rate": [0.01, 0.1, 0.2],
        "clf__reg_alpha": [0, 0.1, 1],
        "clf__reg_lambda": [0, 0.1, 1],
    },
)

# LightGBM
pipe_lgb, params_lgb = make_pipeline(
    LGBMClassifier(
        objective="multiclass",
        random_state=42,
        class_weight="balanced",
        verbose=-1,
        device="gpu",  # GPU ì‚¬ìš©
        gpu_platform_id=0,  # GPU í”Œë«í¼ ID
        gpu_device_id=0,  # GPU ë””ë°”ì´ìŠ¤ ID
        force_col_wise=True,  # GPU ìµœì í™”
        gpu_use_dp=False,  # ë‹¨ì •ë°€ë„ ì‚¬ìš©ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½
        max_bin=255,  # GPU ìµœì í™”
        num_leaves=31,  # ê³ ì •ê°’ìœ¼ë¡œ ê²½ê³  ì œê±°
        min_child_samples=20,  # ê³ ì •ê°’ìœ¼ë¡œ ê²½ê³  ì œê±°
        subsample=1.0,  # ê³ ì •ê°’ìœ¼ë¡œ ê²½ê³  ì œê±°
        colsample_bytree=1.0,  # ê³ ì •ê°’ìœ¼ë¡œ ê²½ê³  ì œê±°
        # ì„±ëŠ¥ ê°œì„ ì„ ìœ„í•œ ì¶”ê°€ ì„¤ì •
        n_jobs=1,  # GPU ì‚¬ìš©ì‹œ ë‹¨ì¼ ìŠ¤ë ˆë“œ
        deterministic=True,  # ì¬í˜„ì„± ë³´ì¥
        force_row_wise=False,  # GPU ìµœì í™”
        # GPU ê°•ì œ ì‚¬ìš©ì„ ìœ„í•œ ì¶”ê°€ ì„¤ì •
        gpu_use_dp=False,  # ë‹¨ì •ë°€ë„ ì‚¬ìš©
        gpu_use_dp_for_histogram=False,  # íˆìŠ¤í† ê·¸ë¨ë„ ë‹¨ì •ë°€ë„
        gpu_use_dp_for_histogram_bin=False,  # íˆìŠ¤í† ê·¸ë¨ ë¹ˆë„ë„ ë‹¨ì •ë°€ë„
        gpu_use_dp_for_histogram_bin_leaf=False,  # ë¦¬í”„ë³„ íˆìŠ¤í† ê·¸ë¨ë„ ë‹¨ì •ë°€ë„
        gpu_use_dp_for_histogram_bin_leaf_grad=False,  # ê·¸ë˜ë””ì–¸íŠ¸ë„ ë‹¨ì •ë°€ë„
        gpu_use_dp_for_histogram_bin_leaf_hess=False,  # í—¤ì‹œì•ˆë„ ë‹¨ì •ë°€ë„
        gpu_use_dp_for_histogram_bin_leaf_hess_grad=False,  # í—¤ì‹œì•ˆ ê·¸ë˜ë””ì–¸íŠ¸ë„ ë‹¨ì •ë°€ë„
        gpu_use_dp_for_histogram_bin_leaf_hess_grad_hess=False,  # í—¤ì‹œì•ˆ ê·¸ë˜ë””ì–¸íŠ¸ í—¤ì‹œì•ˆë„ ë‹¨ì •ë°€ë„
    ),
    {
        "select__k": [max_k//4, max_k//2, max_k],
        "clf__n_estimators": [200, 400, 600],
        "clf__max_depth": [3, 6, 9],
        "clf__learning_rate": [0.01, 0.1, 0.2],
        "clf__num_leaves": [31, 63, 127],
    },
)

# Gradient Boosting
pipe_gb, params_gb = make_pipeline(
    GradientBoostingClassifier(random_state=42),
    {
        "select__k": [max_k//4, max_k//2, max_k],
        "clf__n_estimators": [100, 200, 300],
        "clf__max_depth": [3, 6, 9],
        "clf__learning_rate": [0.01, 0.1, 0.2],
    },
)

cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# --------------------------------------------------
# 6) ê·¸ë¦¬ë“œ ì„œì¹˜ ì‹¤í–‰
# --------------------------------------------------
print("=== ëª¨ë¸ í•™ìŠµ ì‹œì‘ ===")
print(f"ì „ì²˜ë¦¬ í›„ í”¼ì²˜ ìˆ˜: {n_features_after_prep}")
print(f"ìµœëŒ€ k ê°’: {max_k}")
print(f"í•™ìŠµ ë°ì´í„° í¬ê¸°: {X_tr.shape}")
print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸°: {X_te.shape}")
print(f"í´ë˜ìŠ¤ ìˆ˜: {len(np.unique(y_tr))}")
print(f"í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜:")
for cls, count in y_tr.value_counts().items():
    print(f"  {cls}: {count}ê°œ")
print()

grids = {}
for i, (name, (pipe, params)) in enumerate(zip(
    ["lr", "rf", "xgb", "lgb", "gb"],
    [
        (pipe_lr, params_lr),
        (pipe_rf, params_rf),
        (pipe_xgb, params_xgb),
        (pipe_lgb, params_lgb),
        (pipe_gb, params_gb),
    ],
), 1):
    print(f"=== ëª¨ë¸ {i}/5: {name.upper()} ëª¨ë¸ í•™ìŠµ ì¤‘... ===")
    print(f"íŒŒë¼ë¯¸í„° ì¡°í•© ìˆ˜: {len([(k, v) for k, v in params.items() for v in v])}")
    print(f"ì˜ˆìƒ í•™ìŠµ ì‹œê°„: ì•½ 1-3ë¶„")
    
    # GPU ì‚¬ìš© í™•ì¸ (XGBoost, LightGBMì˜ ê²½ìš°)
    if name in ['xgb', 'lgb']:
        print(f"ğŸ” {name.upper()} GPU ì‚¬ìš© í™•ì¸ ì¤‘...")
        try:
            result = subprocess.run(['nvidia-smi', '--query-gpu=utilization.gpu', '--format=csv,noheader,nounits'], 
                                  capture_output=True, text=True)
            print(f"nvidia-smi ëª…ë ¹ì–´ ê²°ê³¼: {result.returncode}")
            print(f"nvidia-smi ì¶œë ¥: {result.stdout.strip()}")
            if result.returncode == 0:
                gpu_util = result.stdout.strip()
                print(f"ğŸ–¥ï¸ í•™ìŠµ ì „ GPU ì‚¬ìš©ë¥ : {gpu_util}%")
            else:
                print(f"âŒ nvidia-smi ì˜¤ë¥˜: {result.stderr}")
        except Exception as e:
            print(f"âŒ GPU í™•ì¸ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        
        # GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ë„ í™•ì¸
        try:
            mem_result = subprocess.run(['nvidia-smi', '--query-gpu=memory.used,memory.total', '--format=csv,noheader,nounits'], 
                                      capture_output=True, text=True)
            if mem_result.returncode == 0:
                mem_info = mem_result.stdout.strip().split(',')
                if len(mem_info) >= 2:
                    print(f"ğŸ’¾ GPU ë©”ëª¨ë¦¬: {mem_info[0]}/{mem_info[1]} MB")
        except:
            pass
    
    # CPU ëª¨ë¸ë“¤: ë©€í‹°ì½”ì–´ í™œìš©
    n_jobs = max(1, int(cpu_count * 0.75))  # 75% ì½”ì–´ í™œìš©
    
    grid = GridSearchCV(
        pipe, params, cv=cv, scoring="accuracy", n_jobs=n_jobs, verbose=1
    )
    print(f"GridSearchCV ì‹œì‘...")
    grid.fit(X_tr, y_tr)  # sample_weight ë¯¸ì‚¬ìš©
    grids[name] = grid
    
    # í•™ìŠµ í›„ GPU ì‚¬ìš©ë¥  í™•ì¸
    if name in ['xgb', 'lgb']:
        try:
            result = subprocess.run(['nvidia-smi', '--query-gpu=utilization.gpu', '--format=csv,noheader,nounits'], 
                                  capture_output=True, text=True)
            if result.returncode == 0:
                gpu_util = result.stdout.strip()
                print(f"ğŸ–¥ï¸ í•™ìŠµ í›„ GPU ì‚¬ìš©ë¥ : {gpu_util}%")
        except:
            pass
    
    print(f"âœ… {name.upper()} ìµœì  íŒŒë¼ë¯¸í„°: {grid.best_params_}")
    print(f"âœ… {name.upper()} ìµœì  ì ìˆ˜: {grid.best_score_:.4f}")
    print(f"âœ… {name.upper()} í•™ìŠµ ì™„ë£Œ ({i}/5)")
    print()

# --------------------------------------------------
# 7) ì•™ìƒë¸” (Voting & Stacking)
# --------------------------------------------------
print("=== ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ ì¤‘... ===")

# estimators ì •ì˜
estimators = [(n, grids[n].best_estimator_) for n in ["lr", "rf", "xgb", "lgb", "gb"]]
print(f"ì•™ìƒë¸”ì— ì‚¬ìš©í•  ëª¨ë¸: {[name for name, _ in estimators]}")

print("1/2: Voting Classifier í•™ìŠµ ì¤‘...")
vot = VotingClassifier(estimators=estimators, voting="soft")
vot.fit(X_tr, y_tr)
print("âœ… Voting Classifier ì™„ë£Œ")

print("2/2: Stacking Classifier í•™ìŠµ ì¤‘...")
print("  - ë©”íƒ€ ëª¨ë¸: LogisticRegression")
print("  - êµì°¨ê²€ì¦: 5-fold")
print("  - ë³‘ë ¬ ì²˜ë¦¬: CPU ëª¨ë¸ê³¼ GPU ëª¨ë¸ í˜¼ì¬ë¡œ ì¸í•´ ë‹¨ì¼ ìŠ¤ë ˆë“œ ì‚¬ìš©")

# Stacking: ë³‘ë ¬ ì²˜ë¦¬
n_jobs = max(1, int(cpu_count * 0.5))   # 50% ì½”ì–´ í™œìš©
stack = StackingClassifier(
    estimators=estimators,
    final_estimator=LogisticRegression(max_iter=5000),
    cv=cv,
    n_jobs=n_jobs,
)
stack.fit(X_tr, y_tr)
print("âœ… Stacking Classifier ì™„ë£Œ")
print()

# --------------------------------------------------
# 8) í‰ê°€ í•¨ìˆ˜
# --------------------------------------------------
def eval_model(name, model, X, y_true, w):
    print(f"=== {name} ëª¨ë¸ í‰ê°€ ì¤‘... ===")
    y_pred = model.predict(X)
    proba = model.predict_proba(X) if hasattr(model, "predict_proba") else None

    print(f"\n=== {name} ===")
    acc = accuracy_score(y_true, y_pred, sample_weight=w)
    macro_f1 = f1_score(y_true, y_pred, average="macro", sample_weight=w)
    print(f"Accuracy: {acc:.4f}")
    print(f"Macro-F1: {macro_f1:.4f}")

    if proba is not None:
        # ---- class_order ì•ˆì „ ì¶”ì¶œ ----
        class_order = getattr(model, "orig_classes_", None)
        if class_order is None:
            class_order = getattr(model, "classes_", None)
        if class_order is None:
            class_order = np.unique(y_true)
        # --------------------------------

        top3_acc = top_k_accuracy_score(y_true, proba, k=3, sample_weight=w)
        bal_acc = balanced_accuracy_score(y_true, y_pred, sample_weight=w)
        print(f"Top-3 Accuracy: {top3_acc:.4f}")
        print(f"Balanced Accuracy: {bal_acc:.4f}")

        y_bin = label_binarize(y_true, classes=class_order)
        roc_auc = roc_auc_score(y_bin, proba, average="macro", sample_weight=w)
        print(f"Macro ROC-AUC: {roc_auc:.4f}")

    print("\nClassification Report:")
    print(classification_report(y_true, y_pred, sample_weight=w, digits=3))

print("=== ê¸°ë³¸ ëª¨ë¸ í‰ê°€ ì‹œì‘ ===")
print("í‰ê°€í•  ëª¨ë¸: XGB, LGB, GB, Voting, Stacking")
print()

for i, (nm, mdl) in enumerate([
    ("XGB", grids["xgb"].best_estimator_),
    ("LGB", grids["lgb"].best_estimator_),
    ("GB", grids["gb"].best_estimator_),
    ("Voting", vot),
    ("Stacking", stack),
], 1):
    print(f"--- ëª¨ë¸ {i}/5: {nm} ---")
    eval_model(nm, mdl, X_te, y_te, w_te)
    print()

print("\n" + "="*60)
print("=== ê°œì„ ëœ ìƒ˜í”Œë§ ê¸°ë²• í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
print("="*60)

# 1. ê·¹ë‹¨ì  ê°€ì¤‘ì¹˜ ê³„ì‚°
print("1/3: ê·¹ë‹¨ì  ê°€ì¤‘ì¹˜ ê³„ì‚° ì¤‘...")
# ë¬¸ìì—´ ë¼ë²¨ì„ ì •ìˆ˜ë¡œ ë³€í™˜
le_weights = LabelEncoder()
y_tr_encoded = le_weights.fit_transform(y_tr)
class_counts = np.bincount(y_tr_encoded)
total_samples = len(y_tr_encoded)
extreme_weights = (total_samples / (len(class_counts) * class_counts)) ** 1.5
print(f"ê°€ì¤‘ì¹˜ ë²”ìœ„: {extreme_weights.min():.2f} ~ {extreme_weights.max():.2f}")
print("âœ… ê°€ì¤‘ì¹˜ ê³„ì‚° ì™„ë£Œ")
print()

# 2. ë‹¤ì–‘í•œ ìƒ˜í”Œë§ ê¸°ë²• ì‹œë„
sampling_methods = {
    'adasyn': ADASYN(random_state=42),
    'borderline_smote': BorderlineSMOTE(random_state=42),
    'smote_enn': SMOTEENN(random_state=42)
}

print(f"2/3: {len(sampling_methods)}ê°€ì§€ ìƒ˜í”Œë§ ê¸°ë²• í…ŒìŠ¤íŠ¸")
print(f"í…ŒìŠ¤íŠ¸í•  ê¸°ë²•: {list(sampling_methods.keys())}")
print()

# 3. ê° ë°©ë²•ë³„ë¡œ ëª¨ë¸ í•™ìŠµ ë° í‰ê°€
for i, (name, sampler) in enumerate(sampling_methods.items(), 1):
    print(f"--- ìƒ˜í”Œë§ ê¸°ë²• {i}/{len(sampling_methods)}: {name.upper()} ---")
    print(f"ìƒ˜í”ŒëŸ¬: {type(sampler).__name__}")
    print(f"ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„: ì•½ 30ì´ˆ-1ë¶„")
    
    try:
        # ì „ì²˜ë¦¬ ì ìš©
        print("ì „ì²˜ë¦¬ ì ìš© ì¤‘...")
        X_tr_preprocessed = preprocessor.transform(X_tr)
        print(f"ì „ì²˜ë¦¬ í›„ ë°ì´í„° í¬ê¸°: {X_tr_preprocessed.shape}")
        
        # ìƒ˜í”Œë§ ì ìš© (ì „ì²˜ë¦¬ëœ ë°ì´í„° ì‚¬ìš©)
        print("ìƒ˜í”Œë§ ì ìš© ì¤‘...")
        X_resampled, y_resampled = sampler.fit_resample(X_tr_preprocessed, y_tr)
        print(f"ìƒ˜í”Œë§ í›„ ë°ì´í„° í¬ê¸°: {X_resampled.shape}")
        print(f"ìƒ˜í”Œë§ í›„ í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜:")
        for cls, count in pd.Series(y_resampled).value_counts().items():
            print(f"  {cls}: {count}ê°œ")
        
        # ìƒ˜í”Œë§ í›„ ìƒˆë¡œìš´ ê°€ì¤‘ì¹˜ ê³„ì‚°
        print("ìƒ˜í”Œë§ í›„ ê°€ì¤‘ì¹˜ ê³„ì‚° ì¤‘...")
        le_resampled = LabelEncoder()
        y_resampled_encoded = le_resampled.fit_transform(y_resampled)
        class_counts_resampled = np.bincount(y_resampled_encoded)
        total_samples_resampled = len(y_resampled_encoded)
        resampled_weights = (total_samples_resampled / (len(class_counts_resampled) * class_counts_resampled)) ** 1.5
        sample_weights_resampled = np.array([resampled_weights[label] for label in y_resampled_encoded])
        print(f"ìƒ˜í”Œë§ í›„ ê°€ì¤‘ì¹˜ ë²”ìœ„: {resampled_weights.min():.2f} ~ {resampled_weights.max():.2f}")
        
        # XGBWrapper ì‚¬ìš©í•˜ì—¬ ë¬¸ìì—´ ë¼ë²¨ ì²˜ë¦¬
        pipe = Pipeline([
            ('clf', XGBWrapper(
                eval_metric="mlogloss",
                random_state=42,
                tree_method="hist",  # hist ì‚¬ìš©
                device="cuda",  # ìƒˆë¡œìš´ GPU ì„¤ì • ë°©ì‹
                max_bin=256,  # GPU ë©”ëª¨ë¦¬ ìµœì í™”
                single_precision_histogram=True,  # GPU ë©”ëª¨ë¦¬ ì ˆì•½
                enable_categorical=False,  # ì¹´í…Œê³ ë¦¬í˜• ë¹„í™œì„±í™”
                max_leaves=0,  # GPU ìµœì í™”
                grow_policy="lossguide",  # GPU ìµœì í™”
            ))
        ])
        
        print("ëª¨ë¸ í•™ìŠµ ì¤‘...")
        # GPU ì‚¬ìš©ë¥  í™•ì¸
        try:
            result = subprocess.run(['nvidia-smi', '--query-gpu=utilization.gpu', '--format=csv,noheader,nounits'], 
                                  capture_output=True, text=True)
            if result.returncode == 0:
                gpu_util = result.stdout.strip()
                print(f"ğŸ–¥ï¸ ìƒ˜í”Œë§ í•™ìŠµ ì „ GPU ì‚¬ìš©ë¥ : {gpu_util}%")
        except:
            pass
            
        pipe.fit(X_resampled, y_resampled, clf__sample_weight=sample_weights_resampled)
        
        # í•™ìŠµ í›„ GPU ì‚¬ìš©ë¥  í™•ì¸
        try:
            result = subprocess.run(['nvidia-smi', '--query-gpu=utilization.gpu', '--format=csv,noheader,nounits'], 
                                  capture_output=True, text=True)
            if result.returncode == 0:
                gpu_util = result.stdout.strip()
                print(f"ğŸ–¥ï¸ ìƒ˜í”Œë§ í•™ìŠµ í›„ GPU ì‚¬ìš©ë¥ : {gpu_util}%")
        except:
            pass
            
        print(f"âœ… {name.upper()} í•™ìŠµ ì™„ë£Œ")

        # í‰ê°€ (í…ŒìŠ¤íŠ¸ ë°ì´í„°ë„ ì „ì²˜ë¦¬)
        print(f"{name.upper()} í‰ê°€ ì¤‘...")
        X_te_preprocessed = preprocessor.transform(X_te)
        y_pred = pipe.predict(X_te_preprocessed)
        eval_model(f"{name.upper()}", pipe, X_te_preprocessed, y_te, w_te)
        
    except Exception as e:
        print(f"âŒ {name.upper()} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        print("ë‹¤ìŒ ìƒ˜í”Œë§ ê¸°ë²•ìœ¼ë¡œ ì§„í–‰...")
    
    print()

print("3/3: ëª¨ë“  ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ ì™„ë£Œ")
print("="*60)
print("ğŸ‰ ëª¨ë“  ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
print("="*60)