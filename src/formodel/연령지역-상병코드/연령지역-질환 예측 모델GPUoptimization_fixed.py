import pandas as pd
import numpy as np
import warnings
from sklearn.exceptions import ConvergenceWarning
import subprocess
import os
import multiprocessing
import json
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime

# CUDA í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (GPU ì‚¬ìš© í™œì„±í™” - ë©”ëª¨ë¦¬ íš¨ìœ¨ì )
os.environ['CUDA_VISIBLE_DEVICES'] = '0'
os.environ['XGBOOST_USE_CUDA'] = '1'
os.environ['LIGHTGBM_USE_GPU'] = '1'

# GPU ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì„¤ì •
print("ğŸš€ GPU ëª¨ë“œë¡œ ì‹¤í–‰ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì„¤ì •)")
print("âš ï¸ ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ ìë™ìœ¼ë¡œ CPU ëª¨ë“œë¡œ ì „í™˜ë©ë‹ˆë‹¤.")

# CPU ëª¨ë“œë¡œ ì „í™˜ (ë¹ ë¥¸ ì‹¤í–‰ì„ ìœ„í•´)
print("ğŸš€ CPU ëª¨ë“œë¡œ ì‹¤í–‰ (ë¹ ë¥¸ í•™ìŠµì„ ìœ„í•´)")
print("âš ï¸ GPU ì„¤ì •ì„ ë¹„í™œì„±í™”í•˜ì—¬ ì•ˆì •ì ì¸ ì‹¤í–‰ì„ ë³´ì¥í•©ë‹ˆë‹¤.")

from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV
from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder
from sklearn.feature_selection import SelectKBest, f_classif, VarianceThreshold
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import (
    accuracy_score, f1_score, classification_report,
    top_k_accuracy_score, balanced_accuracy_score, roc_auc_score
)
from sklearn.preprocessing import label_binarize

from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE
from imblearn.pipeline import Pipeline as ImbPipeline
from imblearn.combine import SMOTEENN

from xgboost import XGBClassifier
from lightgbm import LGBMClassifier

# ëª¨ë“  ê²½ê³  ë¬´ì‹œ
warnings.filterwarnings("ignore")

# íŠ¹ì • ê²½ê³ ë§Œ ë¬´ì‹œ (ë” êµ¬ì²´ì ìœ¼ë¡œ)
warnings.filterwarnings("ignore", category=UserWarning, module="sklearn.preprocessing._encoders")
warnings.filterwarnings("ignore", category=UserWarning, module="sklearn.feature_selection._univariate_selection")
warnings.filterwarnings("ignore", category=RuntimeWarning, module="sklearn.feature_selection._univariate_selection")
warnings.filterwarnings("ignore", category=ConvergenceWarning, module="sklearn.linear_model._sag")

# XGBoost ê´€ë ¨ ê²½ê³  ë¬´ì‹œ
warnings.filterwarnings("ignore", category=UserWarning, module="xgboost")
warnings.filterwarnings("ignore", category=FutureWarning, module="xgboost")
warnings.filterwarnings("ignore", category=DeprecationWarning, module="xgboost")

# LightGBM ê´€ë ¨ ê²½ê³  ë¬´ì‹œ
warnings.filterwarnings("ignore", category=UserWarning, module="lightgbm")
warnings.filterwarnings("ignore", category=FutureWarning, module="lightgbm")
warnings.filterwarnings("ignore", category=DeprecationWarning, module="lightgbm")

# ì¶”ê°€ì ì¸ ê²½ê³  ë¬´ì‹œ
warnings.filterwarnings("ignore", message=".*FutureWarning.*")
warnings.filterwarnings("ignore", message=".*DeprecationWarning.*")
warnings.filterwarnings("ignore", message=".*UserWarning.*")

# sklearn ê´€ë ¨ ëª¨ë“  ê²½ê³  ë¬´ì‹œ
warnings.filterwarnings("ignore", category=UserWarning, module="sklearn")
warnings.filterwarnings("ignore", category=FutureWarning, module="sklearn")
warnings.filterwarnings("ignore", category=DeprecationWarning, module="sklearn")
warnings.filterwarnings("ignore", category=ConvergenceWarning, module="sklearn")

# pandas ê´€ë ¨ ê²½ê³  ë¬´ì‹œ
warnings.filterwarnings("ignore", category=UserWarning, module="pandas")
warnings.filterwarnings("ignore", category=FutureWarning, module="pandas")
warnings.filterwarnings("ignore", category=DeprecationWarning, module="pandas")

# numpy ê´€ë ¨ ê²½ê³  ë¬´ì‹œ
warnings.filterwarnings("ignore", category=UserWarning, module="numpy")
warnings.filterwarnings("ignore", category=FutureWarning, module="numpy")
warnings.filterwarnings("ignore", category=RuntimeWarning, module="numpy")

# matplotlib ê´€ë ¨ ê²½ê³  ë¬´ì‹œ
warnings.filterwarnings("ignore", category=UserWarning, module="matplotlib")
warnings.filterwarnings("ignore", category=FutureWarning, module="matplotlib")

# seaborn ê´€ë ¨ ê²½ê³  ë¬´ì‹œ
warnings.filterwarnings("ignore", category=UserWarning, module="seaborn")
warnings.filterwarnings("ignore", category=FutureWarning, module="seaborn")

# imblearn ê´€ë ¨ ê²½ê³  ë¬´ì‹œ
warnings.filterwarnings("ignore", category=UserWarning, module="imblearn")
warnings.filterwarnings("ignore", category=FutureWarning, module="imblearn")
warnings.filterwarnings("ignore", category=DeprecationWarning, module="imblearn")

# scipy ê´€ë ¨ ê²½ê³  ë¬´ì‹œ
warnings.filterwarnings("ignore", category=UserWarning, module="scipy")
warnings.filterwarnings("ignore", category=FutureWarning, module="scipy")
warnings.filterwarnings("ignore", category=RuntimeWarning, module="scipy")

# ëª¨ë“  ëª¨ë“ˆì˜ íŠ¹ì • ê²½ê³  íƒ€ì… ë¬´ì‹œ
warnings.filterwarnings("ignore", category=UserWarning)
warnings.filterwarnings("ignore", category=FutureWarning)
warnings.filterwarnings("ignore", category=DeprecationWarning)
warnings.filterwarnings("ignore", category=RuntimeWarning)
warnings.filterwarnings("ignore", category=ConvergenceWarning)

# íŠ¹ì • ë©”ì‹œì§€ íŒ¨í„´ ë¬´ì‹œ
warnings.filterwarnings("ignore", message=".*convergence.*")
warnings.filterwarnings("ignore", message=".*ConvergenceWarning.*")
warnings.filterwarnings("ignore", message=".*UserWarning.*")
warnings.filterwarnings("ignore", message=".*FutureWarning.*")
warnings.filterwarnings("ignore", message=".*DeprecationWarning.*")
warnings.filterwarnings("ignore", message=".*RuntimeWarning.*")
warnings.filterwarnings("ignore", message=".*The default value of.*")
warnings.filterwarnings("ignore", message=".*will change.*")
warnings.filterwarnings("ignore", message=".*is deprecated.*")
warnings.filterwarnings("ignore", message=".*will be removed.*")
warnings.filterwarnings("ignore", message=".*SettingWithCopyWarning.*")
warnings.filterwarnings("ignore", message=".*DataFrame.*")
warnings.filterwarnings("ignore", message=".*Series.*")
warnings.filterwarnings("ignore", message=".*numpy.*")
warnings.filterwarnings("ignore", message=".*pandas.*")
warnings.filterwarnings("ignore", message=".*sklearn.*")
warnings.filterwarnings("ignore", message=".*xgboost.*")
warnings.filterwarnings("ignore", message=".*lightgbm.*")
warnings.filterwarnings("ignore", message=".*imblearn.*")

# íŠ¹ì • sklearn ê²½ê³ ë“¤ ë¬´ì‹œ
warnings.filterwarnings("ignore", message="k=.*is greater than n_features=.*")
warnings.filterwarnings("ignore", message=".*All the features will be returned.*")
warnings.filterwarnings("ignore", message="Found unknown categories in columns.*")
warnings.filterwarnings("ignore", message=".*These unknown categories will be encoded as all zeros.*")

# sklearn feature_selection ëª¨ë“ˆì˜ íŠ¹ì • ê²½ê³  ë¬´ì‹œ
warnings.filterwarnings("ignore", message=".*k=.*is greater than n_features=.*", module="sklearn.feature_selection._univariate_selection")
warnings.filterwarnings("ignore", message=".*All the features will be returned.*", module="sklearn.feature_selection._univariate_selection")

# sklearn preprocessing ëª¨ë“ˆì˜ íŠ¹ì • ê²½ê³  ë¬´ì‹œ
warnings.filterwarnings("ignore", message=".*Found unknown categories in columns.*", module="sklearn.preprocessing._encoders")
warnings.filterwarnings("ignore", message=".*These unknown categories will be encoded as all zeros.*", module="sklearn.preprocessing._encoders")

# ëª¨ë“  sklearn ê²½ê³  ë¬´ì‹œ (ìµœí›„ì˜ ìˆ˜ë‹¨)
warnings.filterwarnings("ignore", module="sklearn")

# NumPy íƒ€ì…ì„ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ íƒ€ì…ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
def convert_numpy_types(obj):
    """NumPy íƒ€ì…ì„ Python ê¸°ë³¸ íƒ€ì…ìœ¼ë¡œ ë³€í™˜"""
    if isinstance(obj, np.integer):
        return int(obj)
    elif isinstance(obj, np.floating):
        return float(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, dict):
        return {key: convert_numpy_types(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [convert_numpy_types(item) for item in obj]
    else:
        return obj

# GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
try:
    result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)
    if result.returncode == 0:
        print("âœ… GPU ì‚¬ìš© ê°€ëŠ¥: NVIDIA GPUê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print("ğŸš€ GPU ê°€ì†ì´ í™œì„±í™”ë˜ì–´ í•™ìŠµ ì†ë„ê°€ í¬ê²Œ í–¥ìƒë©ë‹ˆë‹¤.")
        
        # CUDA ë²„ì „ í™•ì¸
        try:
            cuda_result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True)
            if cuda_result.returncode == 0:
                cuda_version = cuda_result.stdout.split('release ')[1].split(',')[0]
                print(f"ğŸ”§ CUDA ë²„ì „: {cuda_version}")
        except:
            print("âš ï¸ CUDA ë²„ì „ í™•ì¸ ì‹¤íŒ¨")
        
        # GPU ìƒì„¸ ì •ë³´ ì¶œë ¥
        gpu_info = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total,driver_version', '--format=csv,noheader'], 
                                capture_output=True, text=True)
        if gpu_info.returncode == 0:
            print(f"ğŸ“Š GPU ì •ë³´: {gpu_info.stdout.strip()}")
        
        # ì´ˆê¸° GPU ì‚¬ìš©ë¥  í™•ì¸
        gpu_util = subprocess.run(['nvidia-smi', '--query-gpu=utilization.gpu', '--format=csv,noheader,nounits'], 
                                capture_output=True, text=True)
        if gpu_util.returncode == 0:
            print(f"ğŸ–¥ï¸ ì´ˆê¸° GPU ì‚¬ìš©ë¥ : {gpu_util.stdout.strip()}%")
            
        # í™˜ê²½ ë³€ìˆ˜ í™•ì¸
        print(f"ğŸ”§ CUDA_VISIBLE_DEVICES: {os.environ.get('CUDA_VISIBLE_DEVICES', 'Not set')}")
        print(f"ğŸ”§ XGBOOST_USE_CUDA: {os.environ.get('XGBOOST_USE_CUDA', 'Not set')}")
        print(f"ğŸ”§ LIGHTGBM_USE_GPU: {os.environ.get('LIGHTGBM_USE_GPU', 'Not set')}")
            
    else:
        print("âš ï¸ GPU ì‚¬ìš© ë¶ˆê°€: NVIDIA GPUê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
except:
    print("âš ï¸ GPU ì‚¬ìš© ë¶ˆê°€: nvidia-smi ëª…ë ¹ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print("CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")

print()

# CPU ì½”ì–´ ìˆ˜ í™•ì¸
cpu_count = multiprocessing.cpu_count()
print(f"ğŸ”§ ì‹œìŠ¤í…œ ì •ë³´:")
print(f"  - CPU ì½”ì–´ ìˆ˜: {cpu_count}ê°œ")
print(f"  - GPU ì‚¬ìš©: í™œì„±í™”")
print()

# --------------------------------------------------
# 1) ë°ì´í„° ì ì¬ ë° ê°€ê³µ
# --------------------------------------------------
df = pd.read_csv("new_merged_data/df_result2_with_ì‹¬í‰ì›.csv", dtype=str)
age_cols = ["59ì´í•˜", "60-64", "65-69", "70-79", "80-89", "90ì´ìƒ"]

m = df.melt(
    id_vars=["ë…„ë„", "êµ¬ë¶„", "ì§€ì—­", "ìƒë³‘ì½”ë“œ", "ì§„ë£Œê³¼"],
    value_vars=age_cols,
    var_name="age_group",
    value_name="count",
)
m["count"] = pd.to_numeric(m["count"], errors="coerce").fillna(0).astype(int)
m["ëŒ€í‘œì§„ë£Œê³¼"] = m["ì§„ë£Œê³¼"]
train = m[m["ëŒ€í‘œì§„ë£Œê³¼"].notna()]

# ê°•í™”ëœ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§
train["year_num"] = train["ë…„ë„"].astype(int) - train["ë…„ë„"].astype(int).min()

# ì—°ë ¹ëŒ€ ìˆ˜ì¹˜í™” (ì¤‘ê°„ê°’ ì‚¬ìš©)
age_mapping = {
    "59ì´í•˜": 30, "60-64": 62, "65-69": 67, 
    "70-79": 75, "80-89": 85, "90ì´ìƒ": 95
}
train["age_num"] = train["age_group"].map(age_mapping)

# ì§€ì—­ë³„ íŠ¹ì„± (ëŒ€ë„ì‹œ vs ì¤‘ì†Œë„ì‹œ)
major_cities = ["ì„œìš¸", "ë¶€ì‚°", "ëŒ€êµ¬", "ì¸ì²œ", "ê´‘ì£¼", "ëŒ€ì „"]
train["is_major_city"] = train["ì§€ì—­"].isin(major_cities).astype(int)

# êµ¬ë¶„ë³„ íŠ¹ì„± (ì…ì› vs ì™¸ë˜)
train["is_inpatient"] = (train["êµ¬ë¶„"] == "ì…ì›").astype(int)

# ìƒë³‘ì½”ë“œ ê¸°ë°˜ í”¼ì²˜ (ì²« 3ìë¦¬ë¡œ ê·¸ë£¹í™”)
train["disease_group"] = train["ìƒë³‘ì½”ë“œ"].str[:3]

# ì—°ë„ë³„ íŠ¸ë Œë“œ
train["year_trend"] = train["year_num"] ** 2

# ë³µí•© í”¼ì²˜
train["age_city_interaction"] = train["age_num"] * train["is_major_city"]
train["age_year_interaction"] = train["age_num"] * train["year_num"]

# ì§€ì—­-ì—°ë ¹ëŒ€ ì¡°í•©
train["region_age"] = train["ì§€ì—­"] + "_" + train["age_group"]

X = train[["year_num", "age_num", "is_major_city", "is_inpatient", 
           "year_trend", "age_city_interaction", "age_year_interaction", 
           "ì§€ì—­", "age_group", "êµ¬ë¶„", "disease_group", "region_age"]]
y = train["ëŒ€í‘œì§„ë£Œê³¼"]
w = train["count"]

# --------------------------------------------------
# 2) í•™ìŠµ / ê²€ì¦ ë¶„ë¦¬
# --------------------------------------------------
X_tr, X_te, y_tr, y_te, w_tr, w_te = train_test_split(
    X, y, w, test_size=0.20, stratify=y, random_state=42
)

# --------------------------------------------------
# 3) ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
# --------------------------------------------------
# ìˆ˜ì¹˜í˜• í”¼ì²˜
num_cols = ["year_num", "age_num", "is_major_city", "is_inpatient", 
            "year_trend", "age_city_interaction", "age_year_interaction"]

# ë²”ì£¼í˜• í”¼ì²˜
cat_cols = ["ì§€ì—­", "age_group", "êµ¬ë¶„", "disease_group", "region_age"]

preprocessor = ColumnTransformer(
    [
        ("ohe", OneHotEncoder(drop="first", sparse_output=False, handle_unknown="ignore"), cat_cols),
        ("scale", StandardScaler(), num_cols),
    ]
)

# --------------------------------------------------
# 4) XGBìš© ë˜í¼ í´ë˜ìŠ¤
# --------------------------------------------------
class XGBWrapper(XGBClassifier):
    """ë¬¸ìâ†’ìˆ«ì ë¼ë²¨ì„ ë‚´ë¶€ ë³€í™˜í•˜ê³ , ì›ë³¸ ë¼ë²¨ì€ orig_classes_ì— ì €ì¥"""
    def fit(self, X, y, **kwargs):
        self._le = LabelEncoder()
        y_enc = self._le.fit_transform(y)
        super().fit(X, y_enc, **kwargs)
        self.orig_classes_ = self._le.classes_
        return self

    def predict(self, X):
        return self._le.inverse_transform(super().predict(X))

    def predict_proba(self, X):
        return super().predict_proba(X)

# --------------------------------------------------
# 5) íŒŒì´í”„ë¼ì¸ & ê·¸ë¦¬ë“œ ì •ì˜ í•¨ìˆ˜
# --------------------------------------------------
def make_pipeline(clf, param_grid):
    pipe = ImbPipeline(
        [
            ("prep", preprocessor),
            ("smote", SMOTE(random_state=42)),
            ("variance", VarianceThreshold(threshold=0.01)),  # ìƒìˆ˜ í”¼ì²˜ ì œê±°
            ("select", SelectKBest(f_classif)),
            ("clf", clf),
        ]
    )
    return pipe, param_grid

# k ê°’ì„ ë™ì ìœ¼ë¡œ ì„¤ì •
# preprocessorë¥¼ ë¨¼ì € fitì‹œì¼œì•¼ í•¨
preprocessor.fit(X_tr)
n_features_after_prep = len(preprocessor.get_feature_names_out())  # ì „ì²˜ë¦¬ í›„ í”¼ì²˜ ìˆ˜
max_k = min(n_features_after_prep, 50)  # ìµœëŒ€ 50ê°œë¡œ ì¶•ì†Œ (100 â†’ 50)

# Logistic Regression
pipe_lr, params_lr = make_pipeline(
    LogisticRegression(
        penalty="l1", solver="saga", max_iter=1000, class_weight="balanced"  # max_iter ëŒ€í­ ì¶•ì†Œ
    ),
    {
        "select__k": [max_k],  # ë‹¨ì¼ ê°’ìœ¼ë¡œ ì¶•ì†Œ
        "clf__C": [0.1, 1],  # ì¡°í•© ì¶•ì†Œ
    },
)

# Random Forest
pipe_rf, params_rf = make_pipeline(
    RandomForestClassifier(class_weight="balanced", random_state=42),
    {
        "select__k": [max_k],  # ë‹¨ì¼ ê°’ìœ¼ë¡œ ì¶•ì†Œ
        "clf__n_estimators": [100],  # ë‹¨ì¼ ê°’ìœ¼ë¡œ ì¶•ì†Œ
        "clf__max_depth": [None, 20],  # ì¡°í•© ì¶•ì†Œ
        "clf__min_samples_split": [2],  # ë‹¨ì¼ ê°’ìœ¼ë¡œ ì¶•ì†Œ
    },
)

# XGBoost
pipe_xgb, params_xgb = make_pipeline(
    XGBWrapper(
        eval_metric="mlogloss",
        random_state=42,
        tree_method="hist",  # CPU ì•ˆì „ ëª¨ë“œ
        n_jobs=-1,  # ëª¨ë“  CPU ì½”ì–´ ì‚¬ìš©
        max_bin=128,  # ë©”ëª¨ë¦¬ ì ˆì•½
        enable_categorical=False,  # ì¹´í…Œê³ ë¦¬í˜• ë¹„í™œì„±í™”
        max_leaves=0,  # ê¸°ë³¸ê°’ ì‚¬ìš©
        grow_policy="lossguide",  # ê¸°ë³¸ ì •ì±…
    ),
    {
        "select__k": [max_k],  # ë‹¨ì¼ ê°’ìœ¼ë¡œ ì¶•ì†Œ
        "clf__n_estimators": [100],  # ë‹¨ì¼ ê°’ìœ¼ë¡œ ì¶•ì†Œ
        "clf__max_depth": [3, 6],  # ì¡°í•© ì¶•ì†Œ
        "clf__learning_rate": [0.1],  # ë‹¨ì¼ ê°’ìœ¼ë¡œ ì¶•ì†Œ
        "clf__reg_alpha": [0],  # ë‹¨ì¼ ê°’ìœ¼ë¡œ ì¶•ì†Œ
        "clf__reg_lambda": [0],  # ë‹¨ì¼ ê°’ìœ¼ë¡œ ì¶•ì†Œ
    },
)

# LightGBM
pipe_lgb, params_lgb = make_pipeline(
    LGBMClassifier(
        objective="multiclass",
        random_state=42,
        class_weight="balanced",
        verbose=-1,
        n_jobs=-1,  # ëª¨ë“  CPU ì½”ì–´ ì‚¬ìš©
        force_col_wise=True,  # CPU ìµœì í™”
        max_bin=128,  # ë©”ëª¨ë¦¬ ì ˆì•½
        num_leaves=31,  # ê³ ì •ê°’ìœ¼ë¡œ ê²½ê³  ì œê±°
        min_child_samples=20,  # ê³ ì •ê°’ìœ¼ë¡œ ê²½ê³  ì œê±°
        subsample=1.0,  # ê³ ì •ê°’ìœ¼ë¡œ ê²½ê³  ì œê±°
        colsample_bytree=1.0,  # ê³ ì •ê°’ìœ¼ë¡œ ê²½ê³  ì œê±°
        deterministic=True,  # ì¬í˜„ì„± ë³´ì¥
    ),
    {
        "select__k": [max_k],  # ë‹¨ì¼ ê°’ìœ¼ë¡œ ì¶•ì†Œ
        "clf__n_estimators": [100],  # ë‹¨ì¼ ê°’ìœ¼ë¡œ ì¶•ì†Œ
        "clf__max_depth": [3, 6],  # ì¡°í•© ì¶•ì†Œ
        "clf__learning_rate": [0.1],  # ë‹¨ì¼ ê°’ìœ¼ë¡œ ì¶•ì†Œ
        "clf__num_leaves": [31],  # ë‹¨ì¼ ê°’ìœ¼ë¡œ ì¶•ì†Œ
    },
)

# Gradient Boosting
pipe_gb, params_gb = make_pipeline(
    GradientBoostingClassifier(random_state=42),
    {
        "select__k": [max_k],  # ë‹¨ì¼ ê°’ìœ¼ë¡œ ì¶•ì†Œ
        "clf__n_estimators": [100],  # ë‹¨ì¼ ê°’ìœ¼ë¡œ ì¶•ì†Œ
        "clf__max_depth": [3, 6],  # ì¡°í•© ì¶•ì†Œ
        "clf__learning_rate": [0.1],  # ë‹¨ì¼ ê°’ìœ¼ë¡œ ì¶•ì†Œ
    },
)

cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)  # 5-fold â†’ 3-foldë¡œ ì¶•ì†Œ

# --------------------------------------------------
# 6) ê·¸ë¦¬ë“œ ì„œì¹˜ ì‹¤í–‰
# --------------------------------------------------
print("=== ëª¨ë¸ í•™ìŠµ ì‹œì‘ ===")
print(f"ì „ì²˜ë¦¬ í›„ í”¼ì²˜ ìˆ˜: {n_features_after_prep}")
print(f"ìµœëŒ€ k ê°’: {max_k}")
print(f"í•™ìŠµ ë°ì´í„° í¬ê¸°: {X_tr.shape}")
print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸°: {X_te.shape}")
print(f"í´ë˜ìŠ¤ ìˆ˜: {len(np.unique(y_tr))}")
print(f"í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜:")
for cls, count in y_tr.value_counts().items():
    print(f"  {cls}: {count}ê°œ")
print()

grids = {}
for i, (name, (pipe, params)) in enumerate(zip(
    ["lr", "rf", "xgb", "lgb", "gb"],
    [
        (pipe_lr, params_lr),
        (pipe_rf, params_rf),
        (pipe_xgb, params_xgb),
        (pipe_lgb, params_lgb),
        (pipe_gb, params_gb),
    ],
), 1):
    print(f"=== ëª¨ë¸ {i}/5: {name.upper()} ëª¨ë¸ í•™ìŠµ ì¤‘... ===")
    print(f"íŒŒë¼ë¯¸í„° ì¡°í•© ìˆ˜: {len([(k, v) for k, v in params.items() for v in v])}")
    print(f"ì˜ˆìƒ í•™ìŠµ ì‹œê°„: ì•½ 10-30ì´ˆ (CPU ìµœì í™”)")  # CPU ëª¨ë¸
    
    # CPU ëª¨ë¸ë“¤: ë©€í‹°ì½”ì–´ í™œìš©
    n_jobs = max(1, int(cpu_count * 0.8))  # 80% ì½”ì–´ í™œìš©
    
    grid = GridSearchCV(
        pipe, params, cv=cv, scoring="accuracy", n_jobs=n_jobs, verbose=0
    )
    print(f"GridSearchCV ì‹œì‘...")
    grid.fit(X_tr, y_tr)  # sample_weight ë¯¸ì‚¬ìš©
    grids[name] = grid
    
    print(f"âœ… {name.upper()} ìµœì  íŒŒë¼ë¯¸í„°: {grid.best_params_}")
    print(f"âœ… {name.upper()} ìµœì  ì ìˆ˜: {grid.best_score_:.4f}")
    print(f"âœ… {name.upper()} í•™ìŠµ ì™„ë£Œ ({i}/5)")
    print()

# --------------------------------------------------
# 7) ì•™ìƒë¸” (Voting & Stacking)
# --------------------------------------------------
print("=== ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ ì¤‘... ===")

# estimators ì •ì˜
estimators = [(n, grids[n].best_estimator_) for n in ["lr", "rf", "xgb", "lgb", "gb"]]
print(f"ì•™ìƒë¸”ì— ì‚¬ìš©í•  ëª¨ë¸: {[name for name, _ in estimators]}")

print("1/2: Voting Classifier í•™ìŠµ ì¤‘...")
vot = VotingClassifier(estimators=estimators, voting="soft")
vot.fit(X_tr, y_tr)
print("âœ… Voting Classifier ì™„ë£Œ")

print("2/2: Stacking Classifier í•™ìŠµ ì¤‘...")
print("  - ë©”íƒ€ ëª¨ë¸: LogisticRegression")
print("  - êµì°¨ê²€ì¦: 5-fold")
print("  - ë³‘ë ¬ ì²˜ë¦¬: CPU ëª¨ë¸ê³¼ GPU ëª¨ë¸ í˜¼ì¬ë¡œ ì¸í•´ ë‹¨ì¼ ìŠ¤ë ˆë“œ ì‚¬ìš©")

# Stacking: ë³‘ë ¬ ì²˜ë¦¬
n_jobs = max(1, int(cpu_count * 0.6))   # 60% ì½”ì–´ í™œìš© (50% â†’ 60%)
stack = StackingClassifier(
    estimators=estimators,
    final_estimator=LogisticRegression(max_iter=3000),  # max_iter ì¶•ì†Œ
    cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42),  # 5-fold â†’ 3-fold
    n_jobs=n_jobs,
)
stack.fit(X_tr, y_tr)
print("âœ… Stacking Classifier ì™„ë£Œ")
print()

# --------------------------------------------------
# 8) í‰ê°€ í•¨ìˆ˜
# --------------------------------------------------
def eval_model(name, model, X, y_true, w):
    print(f"=== {name} ëª¨ë¸ í‰ê°€ ì¤‘... ===")
    y_pred = model.predict(X)
    proba = model.predict_proba(X) if hasattr(model, "predict_proba") else None

    print(f"\n=== {name} ===")
    acc = accuracy_score(y_true, y_pred, sample_weight=w)
    macro_f1 = f1_score(y_true, y_pred, average="macro", sample_weight=w)
    print(f"Accuracy: {acc:.4f}")
    print(f"Macro-F1: {macro_f1:.4f}")

    if proba is not None:
        # ---- class_order ì•ˆì „ ì¶”ì¶œ ----
        class_order = getattr(model, "orig_classes_", None)
        if class_order is None:
            class_order = getattr(model, "classes_", None)
        if class_order is None:
            class_order = np.unique(y_true)
        # --------------------------------

        top3_acc = top_k_accuracy_score(y_true, proba, k=3, sample_weight=w)
        bal_acc = balanced_accuracy_score(y_true, y_pred, sample_weight=w)
        print(f"Top-3 Accuracy: {top3_acc:.4f}")
        print(f"Balanced Accuracy: {bal_acc:.4f}")

        y_bin = label_binarize(y_true, classes=class_order)
        roc_auc = roc_auc_score(y_bin, proba, average="macro", sample_weight=w)
        print(f"Macro ROC-AUC: {roc_auc:.4f}")

    print("\nClassification Report:")
    print(classification_report(y_true, y_pred, sample_weight=w, digits=3))

print("=== ê¸°ë³¸ ëª¨ë¸ í‰ê°€ ì‹œì‘ ===")
print("í‰ê°€í•  ëª¨ë¸: XGB, LGB, GB, Voting, Stacking")
print()

for i, (nm, mdl) in enumerate([
    ("XGB", grids["xgb"].best_estimator_),
    ("LGB", grids["lgb"].best_estimator_),
    ("GB", grids["gb"].best_estimator_),
    ("Voting", vot),
    ("Stacking", stack),
], 1):
    print(f"--- ëª¨ë¸ {i}/5: {nm} ---")
    eval_model(nm, mdl, X_te, y_te, w_te)
    print()

print("\n" + "="*60)
print("=== ê°œì„ ëœ ìƒ˜í”Œë§ ê¸°ë²• í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
print("="*60)

# 1. ê·¹ë‹¨ì  ê°€ì¤‘ì¹˜ ê³„ì‚°
print("1/3: ê·¹ë‹¨ì  ê°€ì¤‘ì¹˜ ê³„ì‚° ì¤‘...")
# ë¬¸ìì—´ ë¼ë²¨ì„ ì •ìˆ˜ë¡œ ë³€í™˜
le_weights = LabelEncoder()
y_tr_encoded = le_weights.fit_transform(y_tr)
class_counts = np.bincount(y_tr_encoded)
total_samples = len(y_tr_encoded)
extreme_weights = (total_samples / (len(class_counts) * class_counts)) ** 1.5
print(f"ê°€ì¤‘ì¹˜ ë²”ìœ„: {extreme_weights.min():.2f} ~ {extreme_weights.max():.2f}")
print("âœ… ê°€ì¤‘ì¹˜ ê³„ì‚° ì™„ë£Œ")
print()

# 2. ë‹¤ì–‘í•œ ìƒ˜í”Œë§ ê¸°ë²• ì‹œë„
sampling_methods = {
    'adasyn': ADASYN(random_state=42),
    'borderline_smote': BorderlineSMOTE(random_state=42),
    'smote_enn': SMOTEENN(random_state=42)
}

print(f"2/3: {len(sampling_methods)}ê°€ì§€ ìƒ˜í”Œë§ ê¸°ë²• í…ŒìŠ¤íŠ¸")
print(f"í…ŒìŠ¤íŠ¸í•  ê¸°ë²•: {list(sampling_methods.keys())}")
print()

# 3. ê° ë°©ë²•ë³„ë¡œ ëª¨ë¸ í•™ìŠµ ë° í‰ê°€
for i, (name, sampler) in enumerate(sampling_methods.items(), 1):
    print(f"--- ìƒ˜í”Œë§ ê¸°ë²• {i}/{len(sampling_methods)}: {name.upper()} ---")
    print(f"ìƒ˜í”ŒëŸ¬: {type(sampler).__name__}")
    print(f"ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„: ì•½ 30ì´ˆ-1ë¶„")
    
    try:
        # ì „ì²˜ë¦¬ ì ìš©
        print("ì „ì²˜ë¦¬ ì ìš© ì¤‘...")
        X_tr_preprocessed = preprocessor.transform(X_tr)
        print(f"ì „ì²˜ë¦¬ í›„ ë°ì´í„° í¬ê¸°: {X_tr_preprocessed.shape}")
        
        # ìƒ˜í”Œë§ ì ìš© (ì „ì²˜ë¦¬ëœ ë°ì´í„° ì‚¬ìš©)
        print("ìƒ˜í”Œë§ ì ìš© ì¤‘...")
        X_resampled, y_resampled = sampler.fit_resample(X_tr_preprocessed, y_tr)
        print(f"ìƒ˜í”Œë§ í›„ ë°ì´í„° í¬ê¸°: {X_resampled.shape}")
        print(f"ìƒ˜í”Œë§ í›„ í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜:")
        for cls, count in pd.Series(y_resampled).value_counts().items():
            print(f"  {cls}: {count}ê°œ")
        
        # ìƒ˜í”Œë§ í›„ ìƒˆë¡œìš´ ê°€ì¤‘ì¹˜ ê³„ì‚°
        print("ìƒ˜í”Œë§ í›„ ê°€ì¤‘ì¹˜ ê³„ì‚° ì¤‘...")
        le_resampled = LabelEncoder()
        y_resampled_encoded = le_resampled.fit_transform(y_resampled)
        class_counts_resampled = np.bincount(y_resampled_encoded)
        total_samples_resampled = len(y_resampled_encoded)
        resampled_weights = (total_samples_resampled / (len(class_counts_resampled) * class_counts_resampled)) ** 1.5
        sample_weights_resampled = np.array([resampled_weights[label] for label in y_resampled_encoded])
        print(f"ìƒ˜í”Œë§ í›„ ê°€ì¤‘ì¹˜ ë²”ìœ„: {resampled_weights.min():.2f} ~ {resampled_weights.max():.2f}")
        
        # ëª¨ë¸ í•™ìŠµ
        print("ëª¨ë¸ í•™ìŠµ ì¤‘...")
        print("ì˜ˆìƒ í•™ìŠµ ì‹œê°„: ì•½ 10-20ì´ˆ")
        
        # ê°„ë‹¨í•œ ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸ (ì „ì²˜ë¦¬ëœ ë°ì´í„° ì‚¬ìš©)
        from sklearn.ensemble import RandomForestClassifier
        test_model = RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=-1)
        test_model.fit(X_resampled, y_resampled)
        
        # í‰ê°€
        print("âœ… ADASYN í•™ìŠµ ì™„ë£Œ")
        print("ADASYN í‰ê°€ ì¤‘...")
        
        # ì˜ˆì¸¡
        y_pred = test_model.predict(X_te_preprocessed)
        
        # ì„±ëŠ¥ í‰ê°€
        acc = accuracy_score(y_te, y_pred, sample_weight=w_te)
        macro_f1 = f1_score(y_te, y_pred, average="macro", sample_weight=w_te)
        
        print(f"=== ADASYN ëª¨ë¸ í‰ê°€ ì¤‘... ===")
        print(f"\n=== ADASYN ===")
        print(f"Accuracy: {acc:.4f}")
        print(f"Macro-F1: {macro_f1:.4f}")
        
        if hasattr(test_model, 'predict_proba'):
            proba = test_model.predict_proba(X_te_preprocessed)
            top3_acc = top_k_accuracy_score(y_te, proba, k=3, sample_weight=w_te)
            bal_acc = balanced_accuracy_score(y_te, y_pred, sample_weight=w_te)
            print(f"Top-3 Accuracy: {top3_acc:.4f}")
            print(f"Balanced Accuracy: {bal_acc:.4f}")
            
            # ROC-AUC ê³„ì‚° ì‹œë„
            try:
                class_order = np.unique(y_te)
                y_bin = label_binarize(y_te, classes=class_order)
                roc_auc = roc_auc_score(y_bin, proba, average="macro", sample_weight=w_te)
                print(f"Macro ROC-AUC: {roc_auc:.4f}")
            except Exception as e:
                print(f"Macro ROC-AUC: nan")
        
        print("\nClassification Report:")
        print(classification_report(y_te, y_pred, sample_weight=w_te, digits=3))
        
    except Exception as e:
        print(f"âŒ {name.upper()} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        print("ë‹¤ìŒ ìƒ˜í”Œë§ ê¸°ë²•ìœ¼ë¡œ ì§„í–‰...")
        continue

print("3/3: ëª¨ë“  ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ ì™„ë£Œ")
print("="*60)
print("ğŸ‰ ëª¨ë“  ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
print("="*60)

# --------------------------------------------------
# ë°ì´í„° ì¶”ì¶œ ë° ì €ì¥
# --------------------------------------------------
print("="*60)
print("=== ë°ì´í„° ì¶”ì¶œ ë° ì €ì¥ ì‹œì‘ ===")
print("="*60)

# ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
results_dir = "model_results"
os.makedirs(f"{results_dir}/performance", exist_ok=True)
os.makedirs(f"{results_dir}/features", exist_ok=True)
os.makedirs(f"{results_dir}/predictions", exist_ok=True)
os.makedirs(f"{results_dir}/models", exist_ok=True)

print(f"ğŸ“ ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬: {results_dir}/")

# ê¸°ë³¸ ëª¨ë¸ë“¤
basic_models = {
    "XGB": grids["xgb"].best_estimator_,
    "LGB": grids["lgb"].best_estimator_,
    "GB": grids["gb"].best_estimator_,
    "RF": grids["rf"].best_estimator_,
    "LR": grids["lr"].best_estimator_,
    "Voting": vot,
    "Stacking": stack
}

# 1) ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ê²°ê³¼ ì €ì¥
print("1/6: ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ê²°ê³¼ ì €ì¥ ì¤‘...")

performance_results = {}

for name, model in basic_models.items():
    print(f"  - {name} ëª¨ë¸ ì„±ëŠ¥ ì¶”ì¶œ ì¤‘...")
    
    try:
        # ëª¨ë¸ ì„±ëŠ¥ ì¶”ì¶œ
        y_pred = model.predict(X_te)
        proba = model.predict_proba(X_te) if hasattr(model, "predict_proba") else None
        
        # ê¸°ë³¸ ì§€í‘œ
        acc = accuracy_score(y_te, y_pred, sample_weight=w_te)
        macro_f1 = f1_score(y_te, y_pred, average="macro", sample_weight=w_te)
        
        # ì¶”ê°€ ì§€í‘œ
        bal_acc = balanced_accuracy_score(y_te, y_pred, sample_weight=w_te)
        
        if proba is not None:
            top3_acc = top_k_accuracy_score(y_te, proba, k=3, sample_weight=w_te)
            
            # ROC-AUC ê³„ì‚°
            try:
                class_order = getattr(model, "orig_classes_", None)
                if class_order is None:
                    class_order = getattr(model, "classes_", None)
                if class_order is None:
                    class_order = np.unique(y_te)
                
                y_bin = label_binarize(y_te, classes=class_order)
                roc_auc = roc_auc_score(y_bin, proba, average="macro", sample_weight=w_te)
            except:
                roc_auc = float('nan')
        else:
            top3_acc = float('nan')
            roc_auc = float('nan')
        
        performance_results[name] = {
            "model_name": name,
            "accuracy": acc,
            "macro_f1": macro_f1,
            "top3_accuracy": top3_acc,
            "balanced_accuracy": bal_acc,
            "macro_roc_auc": roc_auc
        }
        
    except Exception as e:
        print(f"  - {name} ëª¨ë¸ ì„±ëŠ¥ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")

# ì„±ëŠ¥ ë¹„êµ CSV ì €ì¥
if performance_results:
    performance_df = pd.DataFrame(performance_results).T
    performance_df.to_csv(f"{results_dir}/performance/model_performance_comparison.csv", encoding='utf-8-sig')

print(f"âœ… ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {results_dir}/performance/")

# 2) ê·¸ë¦¬ë“œ ì„œì¹˜ ê²°ê³¼ ì €ì¥
print("2/6: ê·¸ë¦¬ë“œ ì„œì¹˜ ê²°ê³¼ ì €ì¥ ì¤‘...")

grid_search_results = {}

for name, grid in grids.items():
    print(f"  - {name.upper()} ê·¸ë¦¬ë“œ ì„œì¹˜ ê²°ê³¼ ì¶”ì¶œ ì¤‘...")
    
    # ìµœì  íŒŒë¼ë¯¸í„°
    best_params = grid.best_params_
    
    # ëª¨ë“  íŒŒë¼ë¯¸í„° ì¡°í•©ì˜ ê²°ê³¼
    cv_results = grid.cv_results_
    
    # ê²°ê³¼ ìš”ì•½
    grid_summary = {
        "model_name": name.upper(),
        "best_score": grid.best_score_,
        "best_params": best_params,
        "best_estimator_type": type(grid.best_estimator_).__name__,
        "cv_splits": cv_results.get('split0_test_score', []).shape[0] if 'split0_test_score' in cv_results else 5,
        "total_combinations": len(cv_results['mean_test_score']),
        "mean_test_scores": cv_results['mean_test_score'].tolist(),
        "std_test_scores": cv_results['std_test_score'].tolist(),
        "rank_test_scores": cv_results['rank_test_score'].tolist(),
        "param_combinations": []
    }
    
    # ê° íŒŒë¼ë¯¸í„° ì¡°í•©ë³„ ê²°ê³¼
    for i in range(len(cv_results['mean_test_score'])):
        param_combo = {}
        for param_name in cv_results['params'][i].keys():
            param_combo[param_name] = cv_results['params'][i][param_name]
        
        param_combo.update({
            "mean_test_score": convert_numpy_types(cv_results['mean_test_score'][i]),
            "std_test_score": convert_numpy_types(cv_results['std_test_score'][i]),
            "rank_test_score": convert_numpy_types(cv_results['rank_test_score'][i])
        })
        grid_summary["param_combinations"].append(param_combo)
    
    grid_search_results[name] = convert_numpy_types(grid_summary)

# ê·¸ë¦¬ë“œ ì„œì¹˜ ê²°ê³¼ ì €ì¥
with open(f"{results_dir}/performance/grid_search_results.json", 'w', encoding='utf-8') as f:
    json.dump(grid_search_results, f, ensure_ascii=False, indent=2)

# ìš”ì•½ í…Œì´ë¸” ìƒì„±
grid_summary_df = pd.DataFrame([
    {
        "model": name,
        "best_score": result["best_score"],
        "best_params": str(result["best_params"]),
        "total_combinations": result["total_combinations"]
    }
    for name, result in grid_search_results.items()
])
grid_summary_df.to_csv(f"{results_dir}/performance/grid_search_summary.csv", index=False, encoding='utf-8-sig')

print(f"âœ… ê·¸ë¦¬ë“œ ì„œì¹˜ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {results_dir}/performance/")

# 3) í”¼ì²˜ ì¤‘ìš”ë„ ì €ì¥
print("3/6: í”¼ì²˜ ì¤‘ìš”ë„ ì €ì¥ ì¤‘...")

feature_importance_results = {}

# í”¼ì²˜ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
feature_names = preprocessor.get_feature_names_out()

for name, model in basic_models.items():
    print(f"  - {name} í”¼ì²˜ ì¤‘ìš”ë„ ì¶”ì¶œ ì¤‘...")
    
    # ëª¨ë¸ì—ì„œ í”¼ì²˜ ì¤‘ìš”ë„ ì¶”ì¶œ
    if hasattr(model, 'feature_importances_'):
        # íŠ¸ë¦¬ ê¸°ë°˜ ëª¨ë¸
        importances = model.feature_importances_
    elif hasattr(model, 'coef_'):
        # ì„ í˜• ëª¨ë¸
        importances = np.abs(model.coef_).mean(axis=0)
    else:
        # ì•™ìƒë¸” ëª¨ë¸ì˜ ê²½ìš° ê°œë³„ ëª¨ë¸ë“¤ì˜ ì¤‘ìš”ë„ í‰ê· 
        if hasattr(model, 'estimators_'):
            importances = np.mean([est.feature_importances_ for est in model.estimators_ if hasattr(est, 'feature_importances_')], axis=0)
        else:
            importances = None
    
    if importances is not None:
        # í”¼ì²˜ ì¤‘ìš”ë„ ë°ì´í„°í”„ë ˆì„ ìƒì„±
        importance_df = pd.DataFrame({
            'feature_name': feature_names,
            'importance': importances
        }).sort_values('importance', ascending=False)
        
        feature_importance_results[name] = {
            "model_name": name,
            "feature_importance": importance_df.to_dict('records'),
            "top_features": importance_df.head(20).to_dict('records')
        }
        
        # ê°œë³„ CSV íŒŒì¼ë¡œ ì €ì¥
        importance_df.to_csv(f"{results_dir}/features/{name}_feature_importance.csv", index=False, encoding='utf-8-sig')

# ì „ì²´ í”¼ì²˜ ì¤‘ìš”ë„ ìš”ì•½
if feature_importance_results:
    # ëª¨ë“  ëª¨ë¸ì˜ í”¼ì²˜ ì¤‘ìš”ë„ í‰ê· 
    all_importances = []
    for name, result in feature_importance_results.items():
        importance_df = pd.DataFrame(result["feature_importance"])
        importance_df['model'] = name
        all_importances.append(importance_df)
    
    if all_importances:
        combined_importance = pd.concat(all_importances, ignore_index=True)
        avg_importance = combined_importance.groupby('feature_name')['importance'].agg(['mean', 'std', 'count']).reset_index()
        avg_importance = avg_importance.sort_values('mean', ascending=False)
        avg_importance.to_csv(f"{results_dir}/features/average_feature_importance.csv", index=False, encoding='utf-8-sig')

# í”¼ì²˜ ì¤‘ìš”ë„ ë©”íƒ€ë°ì´í„° ì €ì¥
with open(f"{results_dir}/features/feature_importance_metadata.json", 'w', encoding='utf-8') as f:
    json.dump(feature_importance_results, f, ensure_ascii=False, indent=2)

print(f"âœ… í”¼ì²˜ ì¤‘ìš”ë„ ì €ì¥ ì™„ë£Œ: {results_dir}/features/")

# 4) ì˜ˆì¸¡ í™•ë¥  ë¶„í¬ ì €ì¥
print("4/6: ì˜ˆì¸¡ í™•ë¥  ë¶„í¬ ì €ì¥ ì¤‘...")

prediction_probability_results = {}

for name, model in basic_models.items():
    print(f"  - {name} ì˜ˆì¸¡ í™•ë¥  ë¶„í¬ ì¶”ì¶œ ì¤‘...")
    
    try:
        # ì˜ˆì¸¡ í™•ë¥ 
        proba = model.predict_proba(X_te)
        
        # í´ë˜ìŠ¤ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
        class_names = getattr(model, "orig_classes_", None)
        if class_names is None:
            class_names = getattr(model, "classes_", None)
        if class_names is None:
            class_names = [f"class_{i}" for i in range(proba.shape[1])]
        
        # ì˜ˆì¸¡ í™•ë¥  ë°ì´í„°í”„ë ˆì„ ìƒì„±
        proba_df = pd.DataFrame(proba, columns=class_names)
        proba_df['actual_class'] = y_te.values
        proba_df['predicted_class'] = model.predict(X_te)
        proba_df['confidence'] = proba.max(axis=1)  # ìµœëŒ€ í™•ë¥ ê°’
        proba_df['model'] = name
        
        # Top-3 ì˜ˆì¸¡
        top3_indices = np.argsort(proba, axis=1)[:, -3:][:, ::-1]
        top3_classes = class_names[top3_indices]
        top3_probs = np.take_along_axis(proba, top3_indices, axis=1)
        
        proba_df['top1_class'] = top3_classes[:, 0]
        proba_df['top1_prob'] = top3_probs[:, 0]
        proba_df['top2_class'] = top3_classes[:, 1]
        proba_df['top2_prob'] = top3_probs[:, 1]
        proba_df['top3_class'] = top3_classes[:, 2]
        proba_df['top3_prob'] = top3_probs[:, 2]
        
        # ì‹ ë¢°ë„ êµ¬ê°„ë³„ ë¶„ì„
        confidence_bins = [0, 0.5, 0.7, 0.8, 0.9, 1.0]
        confidence_labels = ['0-0.5', '0.5-0.7', '0.7-0.8', '0.8-0.9', '0.9-1.0']
        proba_df['confidence_bin'] = pd.cut(proba_df['confidence'], bins=confidence_bins, labels=confidence_labels)
        
        # ì‹ ë¢°ë„ êµ¬ê°„ë³„ ì •í™•ë„
        confidence_accuracy = proba_df.groupby('confidence_bin').apply(
            lambda x: (x['actual_class'] == x['predicted_class']).mean()
        ).reset_index()
        confidence_accuracy.columns = ['confidence_bin', 'accuracy']
        
        prediction_probability_results[name] = {
            "model_name": name,
            "class_names": class_names.tolist(),
            "confidence_accuracy": confidence_accuracy.to_dict('records'),
            "probability_stats": {
                "mean_confidence": proba_df['confidence'].mean(),
                "std_confidence": proba_df['confidence'].std(),
                "min_confidence": proba_df['confidence'].min(),
                "max_confidence": proba_df['confidence'].max()
            }
        }
        
        # ê°œë³„ CSV íŒŒì¼ë¡œ ì €ì¥
        proba_df.to_csv(f"{results_dir}/predictions/{name}_prediction_probabilities.csv", index=False, encoding='utf-8-sig')
        
    except Exception as e:
        print(f"  - {name} ì˜ˆì¸¡ í™•ë¥  ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")

# ì˜ˆì¸¡ í™•ë¥  ë©”íƒ€ë°ì´í„° ì €ì¥
with open(f"{results_dir}/predictions/prediction_probability_metadata.json", 'w', encoding='utf-8') as f:
    json.dump(prediction_probability_results, f, ensure_ascii=False, indent=2)

print(f"âœ… ì˜ˆì¸¡ í™•ë¥  ë¶„í¬ ì €ì¥ ì™„ë£Œ: {results_dir}/predictions/")

# 5) í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ë¶„ì„ ì €ì¥
print("5/6: í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ë¶„ì„ ì €ì¥ ì¤‘...")

class_performance_results = {}

for name, model in basic_models.items():
    print(f"  - {name} í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ë¶„ì„ ì¤‘...")
    
    try:
        y_pred = model.predict(X_te)
        
        # í´ë˜ìŠ¤ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
        class_names = getattr(model, "orig_classes_", None)
        if class_names is None:
            class_names = getattr(model, "classes_", None)
        if class_names is None:
            class_names = np.unique(y_te)
        
        # í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ì§€í‘œ
        from sklearn.metrics import precision_recall_fscore_support
        
        precision, recall, f1, support = precision_recall_fscore_support(
            y_te, y_pred, labels=class_names, average=None, sample_weight=w_te
        )
        
        # í´ë˜ìŠ¤ë³„ ì •í™•ë„ ê³„ì‚°
        class_accuracy = {}
        for i, class_name in enumerate(class_names):
            class_mask = (y_te == class_name)
            if class_mask.sum() > 0:
                class_accuracy[class_name] = (y_pred[class_mask] == y_te[class_mask]).mean()
            else:
                class_accuracy[class_name] = 0.0
        
        # í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ë°ì´í„°í”„ë ˆì„
        class_perf_df = pd.DataFrame({
            'class_name': class_names,
            'precision': precision,
            'recall': recall,
            'f1_score': f1,
            'support': support,
            'accuracy': [class_accuracy[cls] for cls in class_names]
        })
        
        class_performance_results[name] = {
            "model_name": name,
            "class_performance": class_perf_df.to_dict('records'),
            "overall_stats": {
                "macro_precision": precision.mean(),
                "macro_recall": recall.mean(),
                "macro_f1": f1.mean(),
                "weighted_f1": np.average(f1, weights=support)
            }
        }
        
        # ê°œë³„ CSV íŒŒì¼ë¡œ ì €ì¥
        class_perf_df.to_csv(f"{results_dir}/performance/{name}_class_performance.csv", index=False, encoding='utf-8-sig')
        
    except Exception as e:
        print(f"  - {name} í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")

# í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ë©”íƒ€ë°ì´í„° ì €ì¥
with open(f"{results_dir}/performance/class_performance_metadata.json", 'w', encoding='utf-8') as f:
    json.dump(class_performance_results, f, ensure_ascii=False, indent=2)

print(f"âœ… í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ë¶„ì„ ì €ì¥ ì™„ë£Œ: {results_dir}/performance/")

# 6) ëª¨ë¸ ì €ì¥
print("6/6: ëª¨ë¸ ì €ì¥ ì¤‘...")

import joblib

for name, model in basic_models.items():
    try:
        model_path = f"{results_dir}/models/{name}_model.pkl"
        joblib.dump(model, model_path)
        print(f"  - {name} ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_path}")
    except Exception as e:
        print(f"  - {name} ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨: {str(e)}")

print(f"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {results_dir}/models/")

print("\n" + "="*60)
print("ğŸ‰ ëª¨ë“  ë¶„ì„ ë° ì €ì¥ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
print("="*60)
print(f"ğŸ“ ê²°ê³¼ íŒŒì¼ ìœ„ì¹˜: {results_dir}/")
print("ğŸ“Š ì„±ëŠ¥ ë¹„êµ: performance/model_performance_comparison.csv")
print("ğŸ” ê·¸ë¦¬ë“œ ì„œì¹˜: performance/grid_search_results.json")
print("ğŸ“ˆ í”¼ì²˜ ì¤‘ìš”ë„: features/")
print("ğŸ¯ ì˜ˆì¸¡ í™•ë¥ : predictions/")
print("ğŸ¥ í´ë˜ìŠ¤ë³„ ì„±ëŠ¥: performance/class_performance_*.csv")
print("ğŸ’¾ ëª¨ë¸ íŒŒì¼: models/")
print("="*60)
