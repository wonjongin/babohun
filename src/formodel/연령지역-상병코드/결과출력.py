import pandas as pd
import numpy as np
import joblib
import warnings
warnings.filterwarnings('ignore')

# XGBWrapper í´ë˜ìŠ¤ ì •ì˜ (ëª¨ë¸ ë¡œë“œì— í•„ìš”)
from xgboost import XGBClassifier
from sklearn.preprocessing import LabelEncoder

class XGBWrapper(XGBClassifier):
    """ë¬¸ìâ†’ìˆ«ì ë¼ë²¨ì„ ë‚´ë¶€ ë³€í™˜í•˜ê³ , ì›ë³¸ ë¼ë²¨ì€ orig_classes_ì— ì €ì¥"""
    def fit(self, X, y, **kwargs):
        self._le = LabelEncoder()
        y_enc = self._le.fit_transform(y)
        super().fit(X, y_enc, **kwargs)
        self.orig_classes_ = self._le.classes_
        return self

    def predict(self, X):
        return self._le.inverse_transform(super().predict(X))

    def predict_proba(self, X):
        return super().predict_proba(X)

print("=== Stacking ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼ ì¶œë ¥ ===")
print("="*50)

# 1. ë°ì´í„° ë¡œë“œ
print("1/5: ë°ì´í„° ë¡œë“œ ì¤‘...")
df = pd.read_csv("new_merged_data/df_result2_with_ì‹¬í‰ì›.csv", dtype=str)
age_cols = ["59ì´í•˜", "60-64", "65-69", "70-79", "80-89", "90ì´ìƒ"]

# 2. ë°ì´í„° ì „ì²˜ë¦¬ (ì›ë³¸ ì½”ë“œì™€ ë™ì¼)
print("2/5: ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")
m = df.melt(
    id_vars=["ë…„ë„", "êµ¬ë¶„", "ì§€ì—­", "ìƒë³‘ì½”ë“œ", "ì§„ë£Œê³¼"],
    value_vars=age_cols,
    var_name="age_group",
    value_name="count",
)
m["count"] = pd.to_numeric(m["count"], errors="coerce").fillna(0).astype(int)
m["ëŒ€í‘œì§„ë£Œê³¼"] = m["ì§„ë£Œê³¼"]
train = m[m["ëŒ€í‘œì§„ë£Œê³¼"].notna()]

# ê°•í™”ëœ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ (ì›ë³¸ê³¼ ë™ì¼)
train["year_num"] = train["ë…„ë„"].astype(int) - train["ë…„ë„"].astype(int).min()

# ì—°ë ¹ëŒ€ ìˆ˜ì¹˜í™” (ì¤‘ê°„ê°’ ì‚¬ìš©)
age_mapping = {
    "59ì´í•˜": 30, "60-64": 62, "65-69": 67, 
    "70-79": 75, "80-89": 85, "90ì´ìƒ": 95
}
train["age_num"] = train["age_group"].map(age_mapping)

# ì§€ì—­ë³„ íŠ¹ì„± (ëŒ€ë„ì‹œ vs ì¤‘ì†Œë„ì‹œ)
major_cities = ["ì„œìš¸", "ë¶€ì‚°", "ëŒ€êµ¬", "ì¸ì²œ", "ê´‘ì£¼", "ëŒ€ì „"]
train["is_major_city"] = train["ì§€ì—­"].isin(major_cities).astype(int)

# êµ¬ë¶„ë³„ íŠ¹ì„± (ì…ì› vs ì™¸ë˜)
train["is_inpatient"] = (train["êµ¬ë¶„"] == "ì…ì›").astype(int)

# ìƒë³‘ì½”ë“œ ê¸°ë°˜ í”¼ì²˜ (ì²« 3ìë¦¬ë¡œ ê·¸ë£¹í™”)
train["disease_group"] = train["ìƒë³‘ì½”ë“œ"].str[:3]

# ì—°ë„ë³„ íŠ¸ë Œë“œ
train["year_trend"] = train["year_num"] ** 2

# ë³µí•© í”¼ì²˜
train["age_city_interaction"] = train["age_num"] * train["is_major_city"]
train["age_year_interaction"] = train["age_num"] * train["year_num"]

# ì§€ì—­-ì—°ë ¹ëŒ€ ì¡°í•©
train["region_age"] = train["ì§€ì—­"] + "_" + train["age_group"]

X = train[["year_num", "age_num", "is_major_city", "is_inpatient", 
           "year_trend", "age_city_interaction", "age_year_interaction", 
           "ì§€ì—­", "age_group", "êµ¬ë¶„", "disease_group", "region_age"]]
y = train["ëŒ€í‘œì§„ë£Œê³¼"]
w = train["count"]

print(f"ë°ì´í„° í¬ê¸°: {X.shape}")
print(f"í´ë˜ìŠ¤ ìˆ˜: {len(np.unique(y))}")

# 3. Stacking ëª¨ë¸ ë¡œë“œ
print("3/5: Stacking ëª¨ë¸ ë¡œë“œ ì¤‘...")
try:
    stacking_model = joblib.load("model_results_ì—°ë ¹ì§€ì—­_ì§„ë£Œê³¼/models/Stacking_model.pkl")
    print("âœ… Stacking ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
except Exception as e:
    print(f"âŒ Stacking ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
    exit()

# 4. ì˜ˆì¸¡ ìˆ˜í–‰
print("4/5: ì˜ˆì¸¡ ìˆ˜í–‰ ì¤‘...")
try:
    # ì˜ˆì¸¡
    y_pred = stacking_model.predict(X)
    y_proba = stacking_model.predict_proba(X)
    
    print("âœ… ì˜ˆì¸¡ ì™„ë£Œ")
    print(f"ì˜ˆì¸¡ëœ í´ë˜ìŠ¤ ìˆ˜: {len(np.unique(y_pred))}")
    
except Exception as e:
    print(f"âŒ ì˜ˆì¸¡ ì‹¤íŒ¨: {str(e)}")
    exit()

# 5. ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
print("5/5: ê²°ê³¼ DataFrame ìƒì„± ì¤‘...")

# ì˜ˆì¸¡ ê²°ê³¼ DataFrame ìƒì„±
result_df = X.copy()

# ì˜ˆì¸¡ ê²°ê³¼ ì¶”ê°€
result_df['y_actual'] = y.values
result_df['y_predicted'] = y_pred
result_df['prediction_correct'] = (y.values == y_pred).astype(int)

# ì˜ˆì¸¡ í™•ë¥  ì¶”ê°€ (ìƒìœ„ 3ê°œ í´ë˜ìŠ¤)
if hasattr(stacking_model, 'classes_'):
    class_names = stacking_model.classes_
elif hasattr(stacking_model, 'orig_classes_'):
    class_names = stacking_model.orig_classes_
else:
    class_names = [f"class_{i}" for i in range(y_proba.shape[1])]

# ìƒìœ„ 3ê°œ ì˜ˆì¸¡ í™•ë¥  ì¶”ê°€
top3_indices = np.argsort(y_proba, axis=1)[:, -3:][:, ::-1]
top3_classes = class_names[top3_indices]
top3_probs = np.take_along_axis(y_proba, top3_indices, axis=1)

result_df['top1_class'] = top3_classes[:, 0]
result_df['top1_probability'] = top3_probs[:, 0]
result_df['top2_class'] = top3_classes[:, 1]
result_df['top2_probability'] = top3_probs[:, 1]
result_df['top3_class'] = top3_classes[:, 2]
result_df['top3_probability'] = top3_probs[:, 2]

# ì‹ ë¢°ë„ (ìµœëŒ€ í™•ë¥ ê°’)
result_df['confidence'] = y_proba.max(axis=1)

# ê°€ì¤‘ì¹˜ ì •ë³´ ì¶”ê°€
result_df['sample_weight'] = w.values

# 6. ê²°ê³¼ ì €ì¥
print("\n=== ê²°ê³¼ ì €ì¥ ===")

# CSV íŒŒì¼ë¡œ ì €ì¥
output_file = "model_results_ì—°ë ¹ì§€ì—­_ì§„ë£Œê³¼/Stacking_prediction_results_detailed.csv"
result_df.to_csv(output_file, encoding='utf-8-sig', index=False)

print(f"âœ… ìƒì„¸ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_file}")
print(f"ğŸ“Š ì´ {len(result_df)}ê°œ ì˜ˆì¸¡ ê²°ê³¼")

# 7. ì„±ëŠ¥ ìš”ì•½ ì¶œë ¥
print("\n=== ì„±ëŠ¥ ìš”ì•½ ===")
from sklearn.metrics import accuracy_score, classification_report

# ì „ì²´ ì„±ëŠ¥
overall_accuracy = accuracy_score(y, y_pred, sample_weight=w)
print(f"ì „ì²´ ì •í™•ë„ (ê°€ì¤‘ì¹˜ ì ìš©): {overall_accuracy:.4f}")

# ê°€ì¤‘ì¹˜ ì ìš©í•˜ì§€ ì•Šì€ ì •í™•ë„
simple_accuracy = accuracy_score(y, y_pred)
print(f"ì „ì²´ ì •í™•ë„ (ê°€ì¤‘ì¹˜ ë¯¸ì ìš©): {simple_accuracy:.4f}")

# ì˜ˆì¸¡ ì‹ ë¢°ë„ í†µê³„
print(f"\nì˜ˆì¸¡ ì‹ ë¢°ë„ í†µê³„:")
print(f"í‰ê·  ì‹ ë¢°ë„: {result_df['confidence'].mean():.4f}")
print(f"ì‹ ë¢°ë„ í‘œì¤€í¸ì°¨: {result_df['confidence'].std():.4f}")
print(f"ìµœì†Œ ì‹ ë¢°ë„: {result_df['confidence'].min():.4f}")
print(f"ìµœëŒ€ ì‹ ë¢°ë„: {result_df['confidence'].max():.4f}")

# ìƒìœ„ ì˜ˆì¸¡ ê²°ê³¼
print(f"\nìƒìœ„ ì˜ˆì¸¡ ê²°ê³¼:")
print(f"Top-1 ì •í™•ë„: {(result_df['y_actual'] == result_df['top1_class']).mean():.4f}")
print(f"Top-2 ì •í™•ë„: {((result_df['y_actual'] == result_df['top1_class']) | (result_df['y_actual'] == result_df['top2_class'])).mean():.4f}")
print(f"Top-3 ì •í™•ë„: {((result_df['y_actual'] == result_df['top1_class']) | (result_df['y_actual'] == result_df['top2_class']) | (result_df['y_actual'] == result_df['top3_class'])).mean():.4f}")

# í´ë˜ìŠ¤ë³„ ì„±ëŠ¥
print(f"\ní´ë˜ìŠ¤ë³„ ì„±ëŠ¥ (ìƒìœ„ 10ê°œ í´ë˜ìŠ¤):")
class_performance = result_df.groupby('y_actual').agg({
    'prediction_correct': 'mean',
    'confidence': 'mean',
    'sample_weight': 'sum'
}).sort_values('sample_weight', ascending=False).head(10)

print(class_performance.round(4))

# 8. ì¶”ê°€ ë¶„ì„ íŒŒì¼ ìƒì„±
print("\n=== ì¶”ê°€ ë¶„ì„ íŒŒì¼ ìƒì„± ===")

# ì‹ ë¢°ë„ êµ¬ê°„ë³„ ì„±ëŠ¥ ë¶„ì„
confidence_bins = [0, 0.5, 0.7, 0.8, 0.9, 1.0]
confidence_labels = ['0-0.5', '0.5-0.7', '0.7-0.8', '0.8-0.9', '0.9-1.0']
result_df['confidence_bin'] = pd.cut(result_df['confidence'], bins=confidence_bins, labels=confidence_labels)

confidence_performance = result_df.groupby('confidence_bin').agg({
    'prediction_correct': 'mean',
    'sample_weight': 'sum'
}).reset_index()
confidence_performance.columns = ['confidence_bin', 'accuracy', 'total_weight']

confidence_file = "model_results_ì—°ë ¹ì§€ì—­_ì§„ë£Œê³¼/Stacking_confidence_analysis.csv"
confidence_performance.to_csv(confidence_file, encoding='utf-8-sig', index=False)
print(f"âœ… ì‹ ë¢°ë„ ë¶„ì„ ì €ì¥: {confidence_file}")

# ì˜¤ë¶„ë¥˜ ë¶„ì„
misclassified = result_df[result_df['prediction_correct'] == 0].copy()
if len(misclassified) > 0:
    misclassified_file = "model_results_ì—°ë ¹ì§€ì—­_ì§„ë£Œê³¼/Stacking_misclassified_cases.csv"
    misclassified.to_csv(misclassified_file, encoding='utf-8-sig', index=False)
    print(f"âœ… ì˜¤ë¶„ë¥˜ ì¼€ì´ìŠ¤ ì €ì¥: {misclassified_file}")
    print(f"ğŸ“Š ì˜¤ë¶„ë¥˜ ì¼€ì´ìŠ¤ ìˆ˜: {len(misclassified)}ê°œ")

print("\n" + "="*50)
print("ğŸ‰ Stacking ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼ ì¶œë ¥ ì™„ë£Œ!")
print("="*50)
print(f"ğŸ“ ì£¼ìš” ê²°ê³¼ íŒŒì¼:")
print(f"  - ìƒì„¸ ì˜ˆì¸¡ ê²°ê³¼: {output_file}")
print(f"  - ì‹ ë¢°ë„ ë¶„ì„: {confidence_file}")
if len(misclassified) > 0:
    print(f"  - ì˜¤ë¶„ë¥˜ ì¼€ì´ìŠ¤: {misclassified_file}")
print("="*50)
