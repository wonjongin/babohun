import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV, KFold
from sklearn.multioutput import MultiOutputRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor
from sklearn.linear_model import Ridge, ElasticNet
from sklearn.neighbors import KNeighborsRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.preprocessing import StandardScaler
import os

# ----------------------
# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ë° ì „ì²˜ë¦¬
# ----------------------
print("=== ë°ì´í„° ë¡œë”© ì‹œì‘ ===")

# ê¸°ë³¸ ë°ì´í„°
data = pd.read_csv("new_merged_data/ë³‘ì›_í†µí•©_ë°ì´í„°.csv")
data = data[~data["ë³‘ì›ëª…"].str.contains("í˜¸ìŠ¤í”¼ìŠ¤")]  # í˜¸ìŠ¤í”¼ìŠ¤ ë³‘ì› ì œì™¸

# ì—°ë ¹ì§€ì—­ ë°ì´í„° ë¡œë“œ (ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•´)
try:
    df_age_region = pd.read_csv('model_results_ì—°ë ¹ì§€ì—­_ì§„ë£Œê³¼/Stacking_prediction_results_detailed.csv')
    print("âœ… ì—°ë ¹ì§€ì—­ ì§„ë£Œê³¼ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
except:
    print("âš ï¸ ì—°ë ¹ì§€ì—­ ì§„ë£Œê³¼ ë°ì´í„° ì—†ìŒ")
    df_age_region = None

# ì‹œê³„ì—´ ì˜ˆì¸¡ ë°ì´í„° ë¡œë“œ (ê°€ëŠ¥í•œ ê²½ìš°)
# try:
#     df_pred = pd.read_csv('analysis_data/ë³‘ì›ë³„_ì§„ë£Œê³¼ë³„_ì…ì›ì™¸ë˜_í†µí•©_ì‹œê³„ì—´ì˜ˆì¸¡ê²°ê³¼_ê°œì„ .csv')
#     print("âœ… ì‹œê³„ì—´ ì˜ˆì¸¡ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
# except:
#     print("âš ï¸ ì‹œê³„ì—´ ì˜ˆì¸¡ ë°ì´í„° ì—†ìŒ")
df_pred = None

print("=== ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘ ===")

bed_columns = [
    "ê²©ë¦¬ë³‘ì‹¤", "ë¬´ê· ì¹˜ë£Œì‹¤", "ë¬¼ë¦¬ì¹˜ë£Œì‹¤", "ë¶„ë§Œì‹¤", "ìˆ˜ìˆ ì‹¤",
    "ì‹ ìƒì•„ì‹¤", "ì‘ê¸‰ì‹¤", "ì¸ê³µì‹ ì¥ì‹¤", "ì¼ë°˜ì…ì›ì‹¤_ìƒê¸‰", "ì¼ë°˜ì…ì›ì‹¤_ì¼ë°˜",
    "ì •ì‹ ê³¼ê°œë°©_ì¼ë°˜", "ì •ì‹ ê³¼íì‡„_ì¼ë°˜", "ì¤‘í™˜ìì‹¤_ì„±ì¸", "íšŒë³µì‹¤"
]

data["ì´ë³‘ìƒìˆ˜"] = data[bed_columns].sum(axis=1)
y = data[bed_columns + ["ì´ë³‘ìƒìˆ˜"]]

# ë³‘ì›ëª… ì •ë³´ë¥¼ ë³„ë„ë¡œ ì €ì¥
hospital_names = data["ë³‘ì›ëª…"].copy()

drop_cols = bed_columns + ["ì´ë³‘ìƒìˆ˜", "ë³‘ì›ëª…"]
X = data.drop(columns=drop_cols)

# ----------------------
# ì—°ë ¹ì§€ì—­ ë°ì´í„° ê¸°ë°˜ ì¶”ê°€ í”¼ì²˜ ìƒì„±
# ----------------------
print("=== ì—°ë ¹ì§€ì—­ ë°ì´í„° ê¸°ë°˜ í”¼ì²˜ ìƒì„± ===")

# 1) ì§€ì—­ ì •ë³´ ì¶”ì¶œ (ë³‘ì›ëª…ì—ì„œ)
X['ì§€ì—­'] = hospital_names.apply(lambda x: 
    'ì„œìš¸' if 'ì„œìš¸' in str(x) else
    'ê´‘ì—­ì‹œ' if any(city in str(x) for city in ['ë¶€ì‚°', 'ëŒ€êµ¬', 'ì¸ì²œ', 'ê´‘ì£¼', 'ëŒ€ì „']) else
    'ê¸°íƒ€'
)

X['ëŒ€ë„ì‹œ'] = X['ì§€ì—­'].apply(lambda x: 1 if x in ['ì„œìš¸', 'ê´‘ì—­ì‹œ'] else 0)

# 2) ë³‘ì› ê·œëª¨ ë¶„ë¥˜
X['ë³‘ì›ê·œëª¨'] = data['ì´ë³‘ìƒìˆ˜'].apply(lambda x: 
    'ëŒ€í˜•' if x >= 1000 else
    'ì¤‘í˜•' if x >= 500 else
    'ì†Œí˜•'
)

# 3) ì—°ë ¹ì§€ì—­ ë°ì´í„°ì—ì„œ ì§„ë£Œê³¼ë³„ ì¸ê¸°ë„ ì •ë³´ ì¶”ê°€
if df_age_region is not None:
    # ì§„ë£Œê³¼ë³„ ì¸ê¸°ë„ ê³„ì‚°
    department_popularity = df_age_region.groupby('y_actual').agg({
        'top1_probability': 'mean',
        'confidence': 'mean',
        'sample_weight': 'sum'
    }).reset_index()
    
    department_popularity.columns = ['ì§„ë£Œê³¼', 'í‰ê· í™•ë¥ ', 'í‰ê· ì‹ ë¢°ë„', 'ì´ìƒ˜í”Œìˆ˜']
    
    # ë³‘ì›ë³„ ì§„ë£Œê³¼ ì •ë³´ê°€ ìˆë‹¤ë©´ ë§¤í•‘
    if 'ì§„ë£Œê³¼' in X.columns:
        X = X.merge(department_popularity, on='ì§„ë£Œê³¼', how='left')
        X['í‰ê· í™•ë¥ '] = X['í‰ê· í™•ë¥ '].fillna(0)
        X['í‰ê· ì‹ ë¢°ë„'] = X['í‰ê· ì‹ ë¢°ë„'].fillna(0)
        X['ì´ìƒ˜í”Œìˆ˜'] = X['ì´ìƒ˜í”Œìˆ˜'].fillna(0)
    else:
        # ì§„ë£Œê³¼ ì •ë³´ê°€ ì—†ìœ¼ë©´ ì „ì²´ í‰ê· ê°’ ì‚¬ìš©
        X['í‰ê· í™•ë¥ '] = department_popularity['í‰ê· í™•ë¥ '].mean()
        X['í‰ê· ì‹ ë¢°ë„'] = department_popularity['í‰ê· ì‹ ë¢°ë„'].mean()
        X['ì´ìƒ˜í”Œìˆ˜'] = department_popularity['ì´ìƒ˜í”Œìˆ˜'].mean()
else:
    X['í‰ê· í™•ë¥ '] = 0
    X['í‰ê· ì‹ ë¢°ë„'] = 0
    X['ì´ìƒ˜í”Œìˆ˜'] = 0

# 4) ì‹œê³„ì—´ ì˜ˆì¸¡ ë°ì´í„° ì¶”ê°€ (ê°€ëŠ¥í•œ ê²½ìš°)
if df_pred is not None:
    # ë³‘ì›ë³„ ì˜ˆì¸¡ ë°ì´í„° í†µí•©
    pred_summary = df_pred.groupby('ë³‘ì›').agg({
        'ARIMAì˜ˆì¸¡': 'mean',
        'RFì˜ˆì¸¡': 'mean',
        'XGBì˜ˆì¸¡': 'mean',
        'ì‹¤ì œê°’': 'mean'
    }).reset_index()
    
    pred_summary.columns = ['ë³‘ì›ëª…', 'ARIMAì˜ˆì¸¡_í‰ê· ', 'RFì˜ˆì¸¡_í‰ê· ', 'XGBì˜ˆì¸¡_í‰ê· ', 'ì‹¤ì œê°’_í‰ê· ']
    
    # ë³‘ì›ëª…ì„ ì¸ë±ìŠ¤ë¡œ ì„¤ì •í•˜ì—¬ ë³‘í•©
    X_with_names = X.copy()
    X_with_names['ë³‘ì›ëª…'] = hospital_names
    X_with_names = X_with_names.merge(pred_summary, on='ë³‘ì›ëª…', how='left')
    X = X_with_names.drop(columns=['ë³‘ì›ëª…'])
    
    # ì˜ˆì¸¡ê°’ ê´€ë ¨ í”¼ì²˜ ìƒì„±
    X['ì˜ˆì¸¡ê°’_í‰ê· '] = X[['ARIMAì˜ˆì¸¡_í‰ê· ', 'RFì˜ˆì¸¡_í‰ê· ', 'XGBì˜ˆì¸¡_í‰ê· ']].mean(axis=1)
    X['ì˜ˆì¸¡ê°’_í‘œì¤€í¸ì°¨'] = X[['ARIMAì˜ˆì¸¡_í‰ê· ', 'RFì˜ˆì¸¡_í‰ê· ', 'XGBì˜ˆì¸¡_í‰ê· ']].std(axis=1)
    X['ê°€ì¤‘ì˜ˆì¸¡ê°’'] = (0.2 * X['ARIMAì˜ˆì¸¡_í‰ê· '] + 0.3 * X['RFì˜ˆì¸¡_í‰ê· '] + 0.5 * X['XGBì˜ˆì¸¡_í‰ê· '])
    
    # NaN ê°’ ì²˜ë¦¬
    X = X.fillna(0)
else:
    # ì˜ˆì¸¡ ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’ ì„¤ì •
    X['ARIMAì˜ˆì¸¡_í‰ê· '] = 0
    X['RFì˜ˆì¸¡_í‰ê· '] = 0
    X['XGBì˜ˆì¸¡_í‰ê· '] = 0
    X['ì‹¤ì œê°’_í‰ê· '] = 0
    X['ì˜ˆì¸¡ê°’_í‰ê· '] = 0
    X['ì˜ˆì¸¡ê°’_í‘œì¤€í¸ì°¨'] = 0
    X['ê°€ì¤‘ì˜ˆì¸¡ê°’'] = 0

# 5) ìƒí˜¸ì‘ìš© í”¼ì²˜ ìƒì„±
X['ì´ë³‘ìƒìˆ˜_ëŒ€ë„ì‹œ'] = data['ì´ë³‘ìƒìˆ˜'] * X['ëŒ€ë„ì‹œ']
X['ì´ë³‘ìƒìˆ˜_í‰ê· í™•ë¥ '] = data['ì´ë³‘ìƒìˆ˜'] * X['í‰ê· í™•ë¥ ']
X['ëŒ€ë„ì‹œ_í‰ê· ì‹ ë¢°ë„'] = X['ëŒ€ë„ì‹œ'] * X['í‰ê· ì‹ ë¢°ë„']

# 6) ë‹¤í•­ì‹ í”¼ì²˜
X['ì´ë³‘ìƒìˆ˜_ì œê³±'] = data['ì´ë³‘ìƒìˆ˜'] ** 2
X['ì´ë³‘ìƒìˆ˜_ì„¸ì œê³±'] = data['ì´ë³‘ìƒìˆ˜'] ** 3

# 7) ë¡œê·¸ ë³€í™˜
X['ì´ë³‘ìƒìˆ˜_log'] = np.log1p(data['ì´ë³‘ìƒìˆ˜'])
X['í‰ê· í™•ë¥ _log'] = np.log1p(np.abs(X['í‰ê· í™•ë¥ ']))
X['ì´ìƒ˜í”Œìˆ˜_log'] = np.log1p(X['ì´ìƒ˜í”Œìˆ˜'])

print(f"ê¸°ì¡´ í”¼ì²˜ ìˆ˜: {len(X.columns) - len(bed_columns) - 1}ê°œ")
print(f"ì¶”ê°€ëœ í”¼ì²˜ ìˆ˜: {len([col for col in X.columns if col not in data.columns])}ê°œ")
print(f"ì´ í”¼ì²˜ ìˆ˜: {len(X.columns)}ê°œ")

# ì›í•« ì¸ì½”ë”©
X = pd.get_dummies(X, drop_first=True)
X.fillna(X.mean(), inplace=True)

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

print(f"ìµœì¢… í”¼ì²˜ ìˆ˜: {X_scaled.shape[1]}ê°œ")

# ----------------------
# êµì°¨ê²€ì¦ìš© KFold ì„¤ì •
# ----------------------
kf = KFold(n_splits=5, shuffle=True, random_state=42)

# ----------------------
# ëª¨ë¸ ë° í•˜ì´í¼íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì •ì˜ (ê°œì„ ëœ ë²„ì „)
# ----------------------
models_and_params = {
    "RandomForest": {
        "model": RandomForestRegressor(random_state=42),
        "params": {
            "estimator__n_estimators": [100, 200],
            "estimator__max_depth": [None, 10, 15],
            "estimator__min_samples_split": [2, 5, 10]
        }
    },
    "GradientBoosting": {
        "model": GradientBoostingRegressor(random_state=42),
        "params": {
            "estimator__n_estimators": [100, 200],
            "estimator__learning_rate": [0.05, 0.1, 0.15],
            "estimator__max_depth": [3, 5, 7]
        }
    },
    "Ridge": {
        "model": Ridge(),
        "params": {
            "estimator__alpha": [0.1, 1.0, 10.0, 100.0]
        }
    },
    "ElasticNet": {
        "model": ElasticNet(random_state=42),
        "params": {
            "estimator__alpha": [0.1, 1.0, 10.0],
            "estimator__l1_ratio": [0.2, 0.5, 0.8]
        }
    },
    "DecisionTree": {
        "model": DecisionTreeRegressor(random_state=42),
        "params": {
            "estimator__max_depth": [None, 10, 15, 20],
            "estimator__min_samples_split": [2, 5, 10],
            "estimator__min_samples_leaf": [1, 2, 4]
        }
    },
    "AdaBoost": {
        "model": AdaBoostRegressor(random_state=42),
        "params": {
            "estimator__n_estimators": [50, 100, 200],
            "estimator__learning_rate": [0.05, 0.1, 0.15]
        }
    },
    "KNN": {
        "model": KNeighborsRegressor(),
        "params": {
            "estimator__n_neighbors": [3, 5, 7, 9],
            "estimator__weights": ['uniform', 'distance']
        }
    }
}

# ----------------------
# ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
# ----------------------
results_dir = "model_results_ì§„ë£Œê³¼ë³„ë³‘ìƒìˆ˜_ì˜ˆì¸¡ëª¨ë¸_ì—°ë ¹ì§€ì—­ì§„ë£Œê³¼ì¶”ê°€"
os.makedirs(results_dir, exist_ok=True)

print(f"ğŸ“ ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬: {results_dir}/")

# ----------------------
# ê·¸ë¦¬ë“œ ì„œì¹˜ + êµì°¨ ê²€ì¦ + í‰ê°€
# ----------------------
results = []
pred_dfs = {}

for name, mp in models_and_params.items():
    print(f"### {name} ëª¨ë¸ ê·¸ë¦¬ë“œ ì„œì¹˜ ë° êµì°¨ê²€ì¦ ì‹œì‘ ###")
    base_model = MultiOutputRegressor(mp["model"])
    grid = GridSearchCV(
        estimator=base_model,
        param_grid=mp["params"],
        cv=kf,
        scoring='neg_mean_squared_error',
        n_jobs=-1,
        verbose=1
    )
    
    try:
        grid.fit(X_scaled, y)
        best_model = grid.best_estimator_
        print(f"Best params for {name}: {grid.best_params_}")
        print(f"Best CV MSE (neg): {grid.best_score_}")

        # ì „ì²´ ë°ì´í„°ë¡œ ì˜ˆì¸¡
        y_pred = best_model.predict(X_scaled)

        for i, col in enumerate(y.columns):
            true_vals = y[col]
            pred_vals = y_pred[:, i]

            mse = mean_squared_error(true_vals, pred_vals)
            mae = mean_absolute_error(true_vals, pred_vals)
            r2 = r2_score(true_vals, pred_vals)

            results.append({
                "ëª¨ë¸": name,
                "ë³‘ìƒì¢…ë¥˜": col,
                "MSE": mse,
                "MAE": mae,
                "R2": r2
            })

        pred_df = y.copy()
        for i, col in enumerate(y.columns):
            pred_df[f"{col}_ì˜ˆì¸¡_{name}"] = y_pred[:, i]
        pred_dfs[name] = pred_df

    except Exception as e:
        print(f"{name} ëª¨ë¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        continue

# ----------------------
# ê²°ê³¼ ì €ì¥ ë° ì¶œë ¥
# ----------------------
print("\n=== ê²°ê³¼ ì €ì¥ ì‹œì‘ ===")

# ì„±ëŠ¥ ë¹„êµ ê²°ê³¼ ì €ì¥
results_df = pd.DataFrame(results)
results_df.to_csv(f"{results_dir}/hospital_bed_model_comparison_metrics_gridcv.csv", encoding="utf-8-sig", index=False)
print(results_df)

# ê°œë³„ ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥
for name, pred_df in pred_dfs.items():
    pred_df.to_csv(f"{results_dir}/hospital_bed_prediction_results_{name}_gridcv.csv", encoding="utf-8-sig", index=True)
    print(f"âœ… {name} ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ì™„ë£Œ")

print(f"\nğŸ‰ ëª¨ë“  ê²°ê³¼ê°€ {results_dir}/ ë””ë ‰í† ë¦¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
print("ğŸ“Š ì„±ëŠ¥ ë¹„êµ: hospital_bed_model_comparison_metrics_gridcv.csv")
print("ğŸ¯ ì˜ˆì¸¡ ê²°ê³¼: hospital_bed_prediction_results_*.csv")
