import warnings
warnings.filterwarnings('ignore')

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score, KFold, cross_val_predict, TimeSeriesSplit, GridSearchCV
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, roc_curve, auc, roc_auc_score
from sklearn.feature_selection import SelectKBest, f_regression, RFE
from sklearn.decomposition import PCA
from sklearn.linear_model import Ridge, Lasso
from sklearn.preprocessing import StandardScaler, RobustScaler
from scipy import stats

from xgboost import XGBRegressor
from lightgbm import LGBMRegressor
from catboost import CatBoostRegressor
from sklearn.ensemble import RandomForestRegressor, VotingRegressor, GradientBoostingRegressor
from sklearn.linear_model import LinearRegression, ElasticNet
from sklearn.svm import SVR
from sklearn.neighbors import KNeighborsRegressor

from optuna import create_study

# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° (ë” í’ë¶€í•œ ë°ì´í„° ì‚¬ìš©)
print("=== ë°ì´í„° ë¡œë”© ì‹œì‘ ===")

# ê¸°ì¡´ ë°ì´í„°
df_info = pd.read_csv('new_merged_data/ë³‘ì›_í†µí•©_ë°ì´í„°.csv')

# ì¶”ê°€ ë°ì´í„° ì†ŒìŠ¤ë“¤
try:
    df_pred = pd.read_csv('analysis_data/ë³‘ì›ë³„_ì§„ë£Œê³¼ë³„_ì…ì›ì™¸ë˜_í†µí•©_ì‹œê³„ì—´ì˜ˆì¸¡ê²°ê³¼_ê°œì„ .csv')
    print("âœ… ì‹œê³„ì—´ ì˜ˆì¸¡ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
except:
    print("âš ï¸ ì‹œê³„ì—´ ì˜ˆì¸¡ ë°ì´í„° ì—†ìŒ, ë‹¤ë¥¸ ë°ì´í„°ë¡œ ëŒ€ì²´")
    df_pred = None

try:
    df_region = pd.read_csv('analysis_data/ì§€ì—­ë³„_ì˜ë£Œí†µê³„.csv')
    print("âœ… ì§€ì—­ë³„ ì˜ë£Œí†µê³„ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
except:
    print("âš ï¸ ì§€ì—­ë³„ ì˜ë£Œí†µê³„ ë°ì´í„° ì—†ìŒ")
    df_region = None

try:
    df_department = pd.read_csv('analysis_data/ì§„ë£Œê³¼ë³„_í†µê³„.csv')
    print("âœ… ì§„ë£Œê³¼ë³„ í†µê³„ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
except:
    print("âš ï¸ ì§„ë£Œê³¼ë³„ í†µê³„ ë°ì´í„° ì—†ìŒ")
    df_department = None

# 2. ë°ì´í„° ì „ì²˜ë¦¬ ë° í†µí•©
print("\n=== ë°ì´í„° ì „ì²˜ë¦¬ ë° í†µí•© ===")

# ë³‘ì› ì •ë³´ ë°ì´í„° ì „ì²˜ë¦¬
df_info['ë³‘ì›ëª…'] = df_info['ë³‘ì›ëª…'].astype(str).str.strip()

# ì§„ë£Œê³¼ë³„ ì „ë¬¸ì˜ìˆ˜ ì»¬ëŸ¼ ì¶”ì¶œ
doc_columns = [col for col in df_info.columns if col.endswith('_ì „ë¬¸ì˜ìˆ˜')]
print(f"ë°œê²¬ëœ ì „ë¬¸ì˜ìˆ˜ ì»¬ëŸ¼: {len(doc_columns)}ê°œ")

# 3. í’ë¶€í•œ í”¼ì²˜ ìƒì„±
print("\n=== í’ë¶€í•œ í”¼ì²˜ ìƒì„± ===")

X_rows = []
y_list = []

# ë³‘ì›ë³„ ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
for idx, row in df_info.iterrows():
    ë³‘ì›ëª… = row['ë³‘ì›ëª…']
    
    # ê° ì§„ë£Œê³¼ë³„ë¡œ ë°ì´í„° ìƒì„±
    for doc_col in doc_columns:
        ì§„ë£Œê³¼ = doc_col.replace('_ì „ë¬¸ì˜ìˆ˜', '')
        ì „ë¬¸ì˜ìˆ˜ = row[doc_col]
        
        if pd.notnull(ì „ë¬¸ì˜ìˆ˜) and ì „ë¬¸ì˜ìˆ˜ > 0:
            # ê¸°ë³¸ ì •ë³´
            row_data = {
                'ë³‘ì›ëª…': ë³‘ì›ëª…,
                'ì§„ë£Œê³¼': ì§„ë£Œê³¼,
                'ì „ë¬¸ì˜ìˆ˜': ì „ë¬¸ì˜ìˆ˜
            }
            
            # 1) ë³‘ìƒìˆ˜ ê´€ë ¨ í”¼ì²˜ (ê¸°ì¡´)
            bed_columns = [
                'ê°•ë‚´ì¹˜ë£Œì‹¤', 'ê²©ë¦¬ë³‘ì‹¤', 'ë¬´ê· ì¹˜ë£Œì‹¤', 'ë¬¼ë¦¬ì¹˜ë£Œì‹¤', 'ë°©ì‚¬ì„ ì˜¥ì†Œ', 'ë¶„ë§Œì‹¤', 'ìˆ˜ìˆ ì‹¤', 'ì‹ ìƒì•„ì‹¤', 
                'ì‘ê¸‰ì‹¤', 'ì¸ê³µì‹ ì¥ì‹¤', 'ì¼ë°˜ì…ì›ì‹¤_ìƒê¸‰', 'ì¼ë°˜ì…ì›ì‹¤_ì¼ë°˜', 'ì •ì‹ ê³¼ê°œë°©_ìƒê¸‰', 'ì •ì‹ ê³¼ê°œë°©_ì¼ë°˜', 
                'ì •ì‹ ê³¼íì‡„_ìƒê¸‰', 'ì •ì‹ ê³¼íì‡„_ì¼ë°˜', 'ì¤‘í™˜ìì‹¤_ì„±ì¸', 'ì¤‘í™˜ìì‹¤_ì†Œì•„', 'ì¤‘í™˜ìì‹¤_ì‹ ìƒì•„', 'íšŒë³µì‹¤',
                'ê°€ì¡±ì‹¤', 'ê°„í˜¸ì‚¬ì‹¤', 'ëª©ìš•ì‹¤', 'ìƒë‹´ì‹¤', 'ì„ì¢…ì‹¤', 'ì²˜ì¹˜ì‹¤', 'í™”ì¥ì‹¤'
            ]
            
            for bed_col in bed_columns:
                if bed_col in row.index:
                    bed_val = row[bed_col]
                    row_data[bed_col] = bed_val if pd.notnull(bed_val) else 0
                else:
                    row_data[bed_col] = 0
            
            # 2) ë³‘ì› ê·œëª¨ ê´€ë ¨ í”¼ì²˜
            total_beds = sum([row_data[col] for col in bed_columns if col in row_data])
            row_data['ì´ë³‘ìƒìˆ˜'] = total_beds
            
            # ë³‘ì› ê·œëª¨ ë¶„ë¥˜
            if total_beds >= 1000:
                row_data['ë³‘ì›ê·œëª¨'] = 'ëŒ€í˜•'
            elif total_beds >= 500:
                row_data['ë³‘ì›ê·œëª¨'] = 'ì¤‘í˜•'
            else:
                row_data['ë³‘ì›ê·œëª¨'] = 'ì†Œí˜•'
            
            # 3) ì§„ë£Œê³¼ë³„ íŠ¹ì„± í”¼ì²˜
            if 'ë‚´ê³¼' in ì§„ë£Œê³¼:
                row_data['ì§„ë£Œê³¼_ë‚´ê³¼ê³„ì—´'] = 1
            elif 'ì™¸ê³¼' in ì§„ë£Œê³¼ or 'ì •í˜•ì™¸ê³¼' in ì§„ë£Œê³¼:
                row_data['ì§„ë£Œê³¼_ì™¸ê³¼ê³„ì—´'] = 1
            elif 'ì†Œì•„' in ì§„ë£Œê³¼:
                row_data['ì§„ë£Œê³¼_ì†Œì•„ê³„ì—´'] = 1
            elif 'ì •ì‹ ' in ì§„ë£Œê³¼:
                row_data['ì§„ë£Œê³¼_ì •ì‹ ê³„ì—´'] = 1
            else:
                row_data['ì§„ë£Œê³¼_ê¸°íƒ€ê³„ì—´'] = 1
            
            # 4) ì§€ì—­ ì •ë³´ (ë³‘ì›ëª…ì—ì„œ ì¶”ì¶œ)
            if 'ì„œìš¸' in ë³‘ì›ëª…:
                row_data['ì§€ì—­'] = 'ì„œìš¸'
                row_data['ëŒ€ë„ì‹œ'] = 1
            elif 'ë¶€ì‚°' in ë³‘ì›ëª… or 'ëŒ€êµ¬' in ë³‘ì›ëª… or 'ì¸ì²œ' in ë³‘ì›ëª… or 'ê´‘ì£¼' in ë³‘ì›ëª… or 'ëŒ€ì „' in ë³‘ì›ëª…:
                row_data['ì§€ì—­'] = 'ê´‘ì—­ì‹œ'
                row_data['ëŒ€ë„ì‹œ'] = 1
            else:
                row_data['ì§€ì—­'] = 'ê¸°íƒ€'
                row_data['ëŒ€ë„ì‹œ'] = 0
            
            # 5) ì‹œê³„ì—´ ì˜ˆì¸¡ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì¶”ê°€
            if df_pred is not None:
                pred_data = df_pred[(df_pred['ë³‘ì›'] == ë³‘ì›ëª…) & (df_pred['ì§„ë£Œê³¼'] == ì§„ë£Œê³¼)]
                if len(pred_data) > 0:
                    pred_row = pred_data.iloc[0]
                    row_data['ARIMAì˜ˆì¸¡'] = pred_row.get('ARIMAì˜ˆì¸¡', 0)
                    row_data['RFì˜ˆì¸¡'] = pred_row.get('RFì˜ˆì¸¡', 0)
                    row_data['XGBì˜ˆì¸¡'] = pred_row.get('XGBì˜ˆì¸¡', 0)
                    row_data['ì‹¤ì œê°’'] = pred_row.get('ì‹¤ì œê°’', 0)
                else:
                    row_data['ARIMAì˜ˆì¸¡'] = 0
                    row_data['RFì˜ˆì¸¡'] = 0
                    row_data['XGBì˜ˆì¸¡'] = 0
                    row_data['ì‹¤ì œê°’'] = 0
            else:
                row_data['ARIMAì˜ˆì¸¡'] = 0
                row_data['RFì˜ˆì¸¡'] = 0
                row_data['XGBì˜ˆì¸¡'] = 0
                row_data['ì‹¤ì œê°’'] = 0
            
            # 6) ì¶”ê°€ í†µê³„ í”¼ì²˜
            row_data['ë³‘ìƒë‹¹ì „ë¬¸ì˜ìˆ˜'] = ì „ë¬¸ì˜ìˆ˜ / (total_beds + 1)
            row_data['ì¤‘í™˜ìì‹¤ë¹„ìœ¨'] = (row_data.get('ì¤‘í™˜ìì‹¤_ì„±ì¸', 0) + row_data.get('ì¤‘í™˜ìì‹¤_ì†Œì•„', 0)) / (total_beds + 1)
            row_data['ì¼ë°˜ì…ì›ì‹¤ë¹„ìœ¨'] = (row_data.get('ì¼ë°˜ì…ì›ì‹¤_ìƒê¸‰', 0) + row_data.get('ì¼ë°˜ì…ì›ì‹¤_ì¼ë°˜', 0)) / (total_beds + 1)
            
            X_rows.append(row_data)
            y_list.append(ì „ë¬¸ì˜ìˆ˜)

X = pd.DataFrame(X_rows)
y = pd.Series(y_list, name='ì „ë¬¸ì˜ìˆ˜')

print(f"ìƒì„±ëœ ë°ì´í„° í¬ê¸°: {X.shape}")
print(f"íƒ€ê²Ÿ ë¶„í¬:\n{y.describe()}")

# 4. ê³ ê¸‰ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§
print("\n=== ê³ ê¸‰ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ===")

# 1) ì‹œê³„ì—´ ì˜ˆì¸¡ ê´€ë ¨ í”¼ì²˜ (ìˆëŠ” ê²½ìš°)
if 'ARIMAì˜ˆì¸¡' in X.columns and 'RFì˜ˆì¸¡' in X.columns and 'XGBì˜ˆì¸¡' in X.columns:
    # ì˜ˆì¸¡ê°’ í†µê³„
    X['ì˜ˆì¸¡ê°’_í‰ê· '] = X[['ARIMAì˜ˆì¸¡', 'RFì˜ˆì¸¡', 'XGBì˜ˆì¸¡']].mean(axis=1)
    X['ì˜ˆì¸¡ê°’_í‘œì¤€í¸ì°¨'] = X[['ARIMAì˜ˆì¸¡', 'RFì˜ˆì¸¡', 'XGBì˜ˆì¸¡']].std(axis=1)
    X['ì˜ˆì¸¡ê°’_ìµœëŒ€'] = X[['ARIMAì˜ˆì¸¡', 'RFì˜ˆì¸¡', 'XGBì˜ˆì¸¡']].max(axis=1)
    X['ì˜ˆì¸¡ê°’_ìµœì†Œ'] = X[['ARIMAì˜ˆì¸¡', 'RFì˜ˆì¸¡', 'XGBì˜ˆì¸¡']].min(axis=1)
    
    # ê°€ì¤‘ ì˜ˆì¸¡ê°’
    X['ê°€ì¤‘ì˜ˆì¸¡ê°’'] = (0.2 * X['ARIMAì˜ˆì¸¡'] + 0.3 * X['RFì˜ˆì¸¡'] + 0.5 * X['XGBì˜ˆì¸¡'])
    
    # ì˜ˆì¸¡ ì •í™•ë„ ì§€í‘œ
    X['ARIMA_ì˜¤ì°¨'] = abs(X['ARIMAì˜ˆì¸¡'] - X['ì‹¤ì œê°’'])
    X['RF_ì˜¤ì°¨'] = abs(X['RFì˜ˆì¸¡'] - X['ì‹¤ì œê°’'])
    X['XGB_ì˜¤ì°¨'] = abs(X['XGBì˜ˆì¸¡'] - X['ì‹¤ì œê°’'])
    
    # ë¡œê·¸ ë³€í™˜
    X['ARIMAì˜ˆì¸¡_log'] = np.log1p(np.abs(X['ARIMAì˜ˆì¸¡']))
    X['RFì˜ˆì¸¡_log'] = np.log1p(np.abs(X['RFì˜ˆì¸¡']))
    X['XGBì˜ˆì¸¡_log'] = np.log1p(np.abs(X['XGBì˜ˆì¸¡']))
    X['ì‹¤ì œê°’_log'] = np.log1p(np.abs(X['ì‹¤ì œê°’']))
    
    # ë¹„ìœ¨ í”¼ì²˜
    X['ARIMA_ë¹„ìœ¨'] = np.where(X['ì‹¤ì œê°’'] != 0, X['ARIMAì˜ˆì¸¡'] / X['ì‹¤ì œê°’'], 1.0)
    X['RF_ë¹„ìœ¨'] = np.where(X['ì‹¤ì œê°’'] != 0, X['RFì˜ˆì¸¡'] / X['ì‹¤ì œê°’'], 1.0)
    X['XGB_ë¹„ìœ¨'] = np.where(X['ì‹¤ì œê°’'] != 0, X['XGBì˜ˆì¸¡'] / X['ì‹¤ì œê°’'], 1.0)

# 2) ë³‘ìƒìˆ˜ ê´€ë ¨ ê³ ê¸‰ í”¼ì²˜
X['ë³‘ìƒë‹¹ì˜ˆì¸¡í™˜ììˆ˜'] = X.get('ê°€ì¤‘ì˜ˆì¸¡ê°’', X['ì´ë³‘ìƒìˆ˜']) / (X['ì´ë³‘ìƒìˆ˜'] + 1)

# ë³‘ìƒìˆ˜ ë¹„ìœ¨ë“¤
bed_ratio_columns = [
    'ì¤‘í™˜ìì‹¤ë¹„ìœ¨', 'ì¼ë°˜ì…ì›ì‹¤ë¹„ìœ¨', 'ë³‘ìƒë‹¹ì „ë¬¸ì˜ìˆ˜'
]

# 3) ìƒí˜¸ì‘ìš© í”¼ì²˜
X['ì´ë³‘ìƒìˆ˜_ëŒ€ë„ì‹œ'] = X['ì´ë³‘ìƒìˆ˜'] * X['ëŒ€ë„ì‹œ']
X['ë³‘ìƒë‹¹ì „ë¬¸ì˜ìˆ˜_ëŒ€ë„ì‹œ'] = X['ë³‘ìƒë‹¹ì „ë¬¸ì˜ìˆ˜'] * X['ëŒ€ë„ì‹œ']

# 4) ë‹¤í•­ì‹ í”¼ì²˜
X['ì´ë³‘ìƒìˆ˜_ì œê³±'] = X['ì´ë³‘ìƒìˆ˜'] ** 2
X['ì´ë³‘ìƒìˆ˜_ì„¸ì œê³±'] = X['ì´ë³‘ìƒìˆ˜'] ** 3

# 5) ë¡œê·¸ ë³€í™˜ (í° ê°’ë“¤ì˜ ì˜í–¥ ì¤„ì´ê¸°)
X['ì´ë³‘ìƒìˆ˜_log'] = np.log1p(X['ì´ë³‘ìƒìˆ˜'])
X['ë³‘ìƒë‹¹ì „ë¬¸ì˜ìˆ˜_log'] = np.log1p(np.abs(X['ë³‘ìƒë‹¹ì „ë¬¸ì˜ìˆ˜']))

# 6) ë²”ì£¼í˜• ë³€ìˆ˜ ì›í•« ì¸ì½”ë”©
categorical_columns = ['ë³‘ì›ëª…', 'ì§„ë£Œê³¼', 'ë³‘ì›ê·œëª¨', 'ì§€ì—­']
X = pd.get_dummies(X, columns=categorical_columns, drop_first=True)

print(f"í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ í›„ ì´ í”¼ì²˜ ìˆ˜: {X.shape[1]}ê°œ")

# 5. ë°ì´í„° ì •ì œ
print("\n=== ë°ì´í„° ì •ì œ ===")

# NaN ê°’ ì²˜ë¦¬
X = X.fillna(0)

# ë¬´í•œëŒ€ ê°’ ì²˜ë¦¬
X = X.replace([np.inf, -np.inf], 0)

# ì´ìƒì¹˜ ì œê±° (99% ë¶„ìœ„ìˆ˜)
numeric_columns = X.select_dtypes(include=[np.number]).columns
for col in numeric_columns:
    if col != 'ì „ë¬¸ì˜ìˆ˜':  # íƒ€ê²Ÿ ë³€ìˆ˜ëŠ” ì œì™¸
        q99 = X[col].quantile(0.99)
        X[col] = np.where(X[col] > q99, q99, X[col])
        X[col] = np.abs(X[col])  # ìŒìˆ˜ ê°’ ì²˜ë¦¬

print("ë°ì´í„° ì •ì œ ì™„ë£Œ")

# 6. ê³ ê¸‰ ëª¨ë¸ë§
print("\n=== ê³ ê¸‰ ëª¨ë¸ë§ ì‹œì‘ ===")

# ë°ì´í„° ë¶„í• 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=None)

print(f"í›ˆë ¨ ë°ì´í„° í¬ê¸°: {X_train.shape}")
print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸°: {X_test.shape}")

# ê³ ê¸‰ ëª¨ë¸ ë¦¬ìŠ¤íŠ¸
models_advanced = {
    'XGBoost': XGBRegressor(
        random_state=42, 
        n_estimators=200, 
        max_depth=6, 
        learning_rate=0.1,
        subsample=0.8,
        colsample_bytree=0.8,
        reg_alpha=0.1,
        reg_lambda=1.0
    ),
    'LightGBM': LGBMRegressor(
        verbose=-1, 
        random_state=42, 
        n_estimators=200, 
        max_depth=6,
        learning_rate=0.1,
        subsample=0.8,
        colsample_bytree=0.8,
        reg_alpha=0.1,
        reg_lambda=1.0
    ),
    'CatBoost': CatBoostRegressor(
        verbose=0, 
        random_state=42, 
        iterations=200, 
        depth=6,
        learning_rate=0.1,
        l2_leaf_reg=3.0
    ),
    'RandomForest': RandomForestRegressor(
        random_state=42, 
        n_estimators=200, 
        max_depth=10,
        min_samples_split=5,
        min_samples_leaf=2,
        max_features='sqrt'
    ),
    'GradientBoosting': GradientBoostingRegressor(
        random_state=42,
        n_estimators=200,
        max_depth=6,
        learning_rate=0.1,
        subsample=0.8
    ),
    'ElasticNet': ElasticNet(
        random_state=42,
        alpha=0.1,
        l1_ratio=0.5,
        max_iter=2000
    ),
    'SVR': SVR(
        kernel='rbf',
        C=1.0,
        gamma='scale'
    ),
    'KNN': KNeighborsRegressor(
        n_neighbors=5,
        weights='distance'
    )
}

# êµì°¨ê²€ì¦ ë° í‰ê°€
cv = KFold(n_splits=5, shuffle=True, random_state=42)

print("\n=== ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ===")
model_results = {}

for name, model in models_advanced.items():
    print(f"\n--- {name} ---")
    
    try:
        # êµì°¨ê²€ì¦
        r2_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='r2')
        rmse_scores = np.sqrt(-cross_val_score(model, X_train, y_train, cv=cv, scoring='neg_mean_squared_error'))
        mae_scores = -cross_val_score(model, X_train, y_train, cv=cv, scoring='neg_mean_absolute_error')
        
        print(f'  CV RÂ²:   {r2_scores.mean():.4f} Â± {r2_scores.std():.4f}')
        print(f'  CV RMSE: {rmse_scores.mean():.4f} Â± {rmse_scores.std():.4f}')
        print(f'  CV MAE:  {mae_scores.mean():.4f} Â± {mae_scores.std():.4f}')
        
        model_results[name] = {
            'r2_mean': r2_scores.mean(),
            'r2_std': r2_scores.std(),
            'rmse_mean': rmse_scores.mean(),
            'rmse_std': rmse_scores.std(),
            'mae_mean': mae_scores.mean(),
            'mae_std': mae_scores.std()
        }
        
    except Exception as e:
        print(f'  ì˜¤ë¥˜ ë°œìƒ: {str(e)}')
        continue

# 7. ì•™ìƒë¸” ëª¨ë¸
print("\n=== ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ ===")

# ê°œë³„ ëª¨ë¸ í•™ìŠµ
trained_models = {}
for name, model in models_advanced.items():
    try:
        model.fit(X_train, y_train)
        trained_models[name] = model
        print(f"âœ… {name} í•™ìŠµ ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ {name} í•™ìŠµ ì‹¤íŒ¨: {str(e)}")
        continue

# ì„±ëŠ¥ ê¸°ë°˜ ê°€ì¤‘ ì•™ìƒë¸”
if len(trained_models) >= 3:
    # RÂ² ê¸°ì¤€ìœ¼ë¡œ ìƒìœ„ 3ê°œ ëª¨ë¸ ì„ íƒ
    top_models = sorted(model_results.items(), key=lambda x: x[1]['r2_mean'], reverse=True)[:3]
    
    ensemble_weights = [0.5, 0.3, 0.2]  # ìƒìœ„ ëª¨ë¸ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜
    ensemble_models = [(name, trained_models[name]) for name, _ in top_models]
    
    print(f"ì•™ìƒë¸” ëª¨ë¸: {[name for name, _ in ensemble_models]}")
    print(f"ì•™ìƒë¸” ê°€ì¤‘ì¹˜: {ensemble_weights}")
    
    # ì•™ìƒë¸” ì˜ˆì¸¡
    y_pred_train_ensemble = np.zeros(len(X_train))
    y_pred_test_ensemble = np.zeros(len(X_test))
    
    for (name, model), weight in zip(ensemble_models, ensemble_weights):
        y_pred_train_ensemble += weight * model.predict(X_train)
        y_pred_test_ensemble += weight * model.predict(X_test)
    
    # ì•™ìƒë¸” ì„±ëŠ¥ í‰ê°€
    ensemble_train_r2 = r2_score(y_train, y_pred_train_ensemble)
    ensemble_test_r2 = r2_score(y_test, y_pred_test_ensemble)
    ensemble_train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train_ensemble))
    ensemble_test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test_ensemble))
    
    print(f"ì•™ìƒë¸” ì„±ëŠ¥:")
    print(f"  Train RÂ²: {ensemble_train_r2:.4f}")
    print(f"  Test RÂ²:  {ensemble_test_r2:.4f}")
    print(f"  Train RMSE: {ensemble_train_rmse:.4f}")
    print(f"  Test RMSE:  {ensemble_test_rmse:.4f}")

# 8. ê²°ê³¼ ì €ì¥
print("\n=== ê²°ê³¼ ì €ì¥ ===")

# ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
import os
results_dir = "model_results_ì§„ë£Œê³¼_ì „ë¬¸ì˜_ì—°ë ¹ì§€ì—­ì§„ë£Œê³¼"
os.makedirs(f"{results_dir}/performance", exist_ok=True)
os.makedirs(f"{results_dir}/predictions", exist_ok=True)
os.makedirs(f"{results_dir}/models", exist_ok=True)

# ì„±ëŠ¥ ë¹„êµ ê²°ê³¼ ì €ì¥
if model_results:
    performance_df = pd.DataFrame(model_results).T
    performance_df = performance_df.sort_values('r2_mean', ascending=False)
    
    performance_df.to_csv(f"{results_dir}/performance/model_performance_comparison.csv", encoding='utf-8-sig')
    
    print("\nğŸ“Š ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ (CV RÂ² ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ):")
    print(performance_df[['r2_mean', 'r2_std', 'rmse_mean', 'mae_mean']].round(4))
    
    print(f"âœ… ì„±ëŠ¥ ë¹„êµ ê²°ê³¼ ì €ì¥: {results_dir}/performance/model_performance_comparison.csv")

# ê°œë³„ ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥
for name, model in trained_models.items():
    try:
        y_pred = model.predict(X_test)
        
        pred_df = X_test.copy()
        pred_df['y_actual'] = y_test.values
        pred_df['y_predicted'] = y_pred
        pred_df['prediction_error'] = y_test.values - y_pred
        pred_df['absolute_error'] = np.abs(y_test.values - y_pred)
        pred_df['model'] = name
        
        pred_df.to_csv(f"{results_dir}/predictions/{name}_predictions.csv", encoding='utf-8-sig', index=False)
        print(f"âœ… {name} ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥: {results_dir}/predictions/{name}_predictions.csv")
        
    except Exception as e:
        print(f"âŒ {name} ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {str(e)}")

# ì•™ìƒë¸” ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥
if 'y_pred_test_ensemble' in locals():
    ensemble_pred_df = X_test.copy()
    ensemble_pred_df['y_actual'] = y_test.values
    ensemble_pred_df['y_predicted'] = y_pred_test_ensemble
    ensemble_pred_df['prediction_error'] = y_test.values - y_pred_test_ensemble
    ensemble_pred_df['absolute_error'] = np.abs(y_test.values - y_pred_test_ensemble)
    ensemble_pred_df['model'] = 'Weighted_Ensemble'
    
    ensemble_pred_df.to_csv(f"{results_dir}/predictions/Weighted_Ensemble_predictions.csv", encoding='utf-8-sig', index=False)
    print(f"âœ… ì•™ìƒë¸” ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥: {results_dir}/predictions/Weighted_Ensemble_predictions.csv")

# ëª¨ë¸ ì €ì¥
import joblib
for name, model in trained_models.items():
    try:
        model_path = f"{results_dir}/models/{name}_model.pkl"
        joblib.dump(model, model_path)
        print(f"âœ… {name} ëª¨ë¸ ì €ì¥: {model_path}")
    except Exception as e:
        print(f"âŒ {name} ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨: {str(e)}")

print("\n" + "="*60)
print("ğŸ‰ ê°œì„ ëœ ëª¨ë¸ë§ ì™„ë£Œ!")
print("="*60)
print(f"ğŸ“ ê²°ê³¼ íŒŒì¼ ìœ„ì¹˜: {results_dir}/")
print("ğŸ“Š ì„±ëŠ¥ ë¹„êµ: performance/model_performance_comparison.csv")
print("ğŸ¯ ì˜ˆì¸¡ ê²°ê³¼: predictions/")
print("ğŸ’¾ ëª¨ë¸ íŒŒì¼: models/")

# ìµœì¢… ì„±ëŠ¥ ìš”ì•½
if model_results:
    best_model_name = performance_df.index[0]
    best_performance = performance_df.loc[best_model_name]
    
    print(f"\nğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model_name}")
    print(f"   - CV RÂ²: {best_performance['r2_mean']:.4f} Â± {best_performance['r2_std']:.4f}")
    print(f"   - CV RMSE: {best_performance['rmse_mean']:.4f} Â± {best_performance['rmse_std']:.4f}")
    print(f"   - CV MAE: {best_performance['mae_mean']:.4f} Â± {best_performance['mae_std']:.4f}")

if 'ensemble_test_r2' in locals():
    print(f"\nğŸ¯ ì•™ìƒë¸” ëª¨ë¸ ì„±ëŠ¥:")
    print(f"   - Test RÂ²: {ensemble_test_r2:.4f}")
    print(f"   - Test RMSE: {ensemble_test_rmse:.4f}")

print("="*60)

'''
=== ë°ì´í„° ë¡œë”© ì‹œì‘ ===
âœ… ì‹œê³„ì—´ ì˜ˆì¸¡ ë°ì´í„° ë¡œë“œ ì™„ë£Œ
âš ï¸ ì§€ì—­ë³„ ì˜ë£Œí†µê³„ ë°ì´í„° ì—†ìŒ
âš ï¸ ì§„ë£Œê³¼ë³„ í†µê³„ ë°ì´í„° ì—†ìŒ

=== ë°ì´í„° ì „ì²˜ë¦¬ ë° í†µí•© ===
ë°œê²¬ëœ ì „ë¬¸ì˜ìˆ˜ ì»¬ëŸ¼: 34ê°œ

=== í’ë¶€í•œ í”¼ì²˜ ìƒì„± ===
ìƒì„±ëœ ë°ì´í„° í¬ê¸°: (128, 46)
íƒ€ê²Ÿ ë¶„í¬:
count    128.000000
mean       3.156250
std        4.563528
min        1.000000
25%        1.000000
50%        2.000000
75%        3.000000
max       47.000000
Name: ì „ë¬¸ì˜ìˆ˜, dtype: float64

=== ê³ ê¸‰ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ===
í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ í›„ ì´ í”¼ì²˜ ìˆ˜: 101ê°œ

=== ë°ì´í„° ì •ì œ ===
ë°ì´í„° ì •ì œ ì™„ë£Œ

=== ê³ ê¸‰ ëª¨ë¸ë§ ì‹œì‘ ===
í›ˆë ¨ ë°ì´í„° í¬ê¸°: (102, 101)
í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸°: (26, 101)

=== ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ===

--- XGBoost ---
  CV RÂ²:   0.8616 Â± 0.2143
  CV RMSE: 1.8098 Â± 2.8042
  CV MAE:  0.4610 Â± 0.6353

--- LightGBM ---
  CV RÂ²:   -0.3756 Â± 1.0564
  CV RMSE: 3.5547 Â± 2.6899
  CV MAE:  1.6389 Â± 0.5950

--- CatBoost ---
  CV RÂ²:   0.6127 Â± 0.3041
  CV RMSE: 2.6713 Â± 3.0004
  CV MAE:  0.8298 Â± 0.6282

--- RandomForest ---
  CV RÂ²:   0.7025 Â± 0.2536
  CV RMSE: 2.4020 Â± 3.1107
  CV MAE:  0.9474 Â± 0.7542

--- GradientBoosting ---
  CV RÂ²:   0.6112 Â± 0.4940
  CV RMSE: 2.4201 Â± 2.9134
  CV MAE:  0.5814 Â± 0.6543

--- ElasticNet ---
  CV RÂ²:   0.9998 Â± 0.0003
  CV RMSE: 0.0594 Â± 0.0982
  CV MAE:  0.0226 Â± 0.0318

--- SVR ---
  CV RÂ²:   0.0377 Â± 0.1340
  CV RMSE: 3.7754 Â± 3.1633
  CV MAE:  1.7404 Â± 0.8313

--- KNN ---
  CV RÂ²:   0.1181 Â± 0.1259
  CV RMSE: 3.5521 Â± 2.8582
  CV MAE:  1.7266 Â± 0.7524

=== ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ ===
âœ… XGBoost í•™ìŠµ ì™„ë£Œ
âœ… LightGBM í•™ìŠµ ì™„ë£Œ
âœ… CatBoost í•™ìŠµ ì™„ë£Œ
âœ… RandomForest í•™ìŠµ ì™„ë£Œ
âœ… GradientBoosting í•™ìŠµ ì™„ë£Œ
âœ… ElasticNet í•™ìŠµ ì™„ë£Œ
âœ… SVR í•™ìŠµ ì™„ë£Œ
âœ… KNN í•™ìŠµ ì™„ë£Œ
ì•™ìƒë¸” ëª¨ë¸: ['ElasticNet', 'XGBoost', 'RandomForest']
ì•™ìƒë¸” ê°€ì¤‘ì¹˜: [0.5, 0.3, 0.2]
ì•™ìƒë¸” ì„±ëŠ¥:
  Train RÂ²: 0.9832
  Test RÂ²:  0.9863
  Train RMSE: 0.6373
  Test RMSE:  0.3041

=== ê²°ê³¼ ì €ì¥ ===

ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ (CV RÂ² ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ):
                  r2_mean  r2_std  rmse_mean  mae_mean
ElasticNet         0.9998  0.0003     0.0594    0.0226
XGBoost            0.8616  0.2143     1.8098    0.4610
RandomForest       0.7025  0.2536     2.4020    0.9474
CatBoost           0.6127  0.3041     2.6713    0.8298
GradientBoosting   0.6112  0.4940     2.4201    0.5814
KNN                0.1181  0.1259     3.5521    1.7266
SVR                0.0377  0.1340     3.7754    1.7404
LightGBM          -0.3756  1.0564     3.5547    1.6389
âœ… ì„±ëŠ¥ ë¹„êµ ê²°ê³¼ ì €ì¥: model_results_ì§„ë£Œê³¼_ì „ë¬¸ì˜_ì—°ë ¹ì§€ì—­ì§„ë£Œê³¼/performance/model_performance_comparison.csv
âœ… XGBoost ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥: model_results_ì§„ë£Œê³¼_ì „ë¬¸ì˜_ì—°ë ¹ì§€ì—­ì§„ë£Œê³¼/predictions/XGBoost_predictions.csv
âœ… LightGBM ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥: model_results_ì§„ë£Œê³¼_ì „ë¬¸ì˜_ì—°ë ¹ì§€ì—­ì§„ë£Œê³¼/predictions/LightGBM_predictions.csv
âœ… CatBoost ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥: model_results_ì§„ë£Œê³¼_ì „ë¬¸ì˜_ì—°ë ¹ì§€ì—­ì§„ë£Œê³¼/predictions/CatBoost_predictions.csv
âœ… RandomForest ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥: model_results_ì§„ë£Œê³¼_ì „ë¬¸ì˜_ì—°ë ¹ì§€ì—­ì§„ë£Œê³¼/predictions/RandomForest_predictions.csv
âœ… GradientBoosting ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥: model_results_ì§„ë£Œê³¼_ì „ë¬¸ì˜_ì—°ë ¹ì§€ì—­ì§„ë£Œê³¼/predictions/GradientBoosting_predictions.csv
âœ… ElasticNet ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥: model_results_ì§„ë£Œê³¼_ì „ë¬¸ì˜_ì—°ë ¹ì§€ì—­ì§„ë£Œê³¼/predictions/ElasticNet_predictions.csv
âœ… SVR ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥: model_results_ì§„ë£Œê³¼_ì „ë¬¸ì˜_ì—°ë ¹ì§€ì—­ì§„ë£Œê³¼/predictions/SVR_predictions.csv
âœ… KNN ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥: model_results_ì§„ë£Œê³¼_ì „ë¬¸ì˜_ì—°ë ¹ì§€ì—­ì§„ë£Œê³¼/predictions/KNN_predictions.csv
âœ… ì•™ìƒë¸” ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥: model_results_ì§„ë£Œê³¼_ì „ë¬¸ì˜_ì—°ë ¹ì§€ì—­ì§„ë£Œê³¼/predictions/Weighted_Ensemble_predictions.csv
âœ… XGBoost ëª¨ë¸ ì €ì¥: model_results_ì§„ë£Œê³¼_ì „ë¬¸ì˜_ì—°ë ¹ì§€ì—­ì§„ë£Œê³¼/models/XGBoost_model.pkl
âœ… LightGBM ëª¨ë¸ ì €ì¥: model_results_ì§„ë£Œê³¼_ì „ë¬¸ì˜_ì—°ë ¹ì§€ì—­ì§„ë£Œê³¼/models/LightGBM_model.pkl
âœ… CatBoost ëª¨ë¸ ì €ì¥: model_results_ì§„ë£Œê³¼_ì „ë¬¸ì˜_ì—°ë ¹ì§€ì—­ì§„ë£Œê³¼/models/CatBoost_model.pkl
âœ… RandomForest ëª¨ë¸ ì €ì¥: model_results_ì§„ë£Œê³¼_ì „ë¬¸ì˜_ì—°ë ¹ì§€ì—­ì§„ë£Œê³¼/models/RandomForest_model.pkl
âœ… GradientBoosting ëª¨ë¸ ì €ì¥: model_results_ì§„ë£Œê³¼_ì „ë¬¸ì˜_ì—°ë ¹ì§€ì—­ì§„ë£Œê³¼/models/GradientBoosting_model.pkl
âœ… ElasticNet ëª¨ë¸ ì €ì¥: model_results_ì§„ë£Œê³¼_ì „ë¬¸ì˜_ì—°ë ¹ì§€ì—­ì§„ë£Œê³¼/models/ElasticNet_model.pkl
âœ… SVR ëª¨ë¸ ì €ì¥: model_results_ì§„ë£Œê³¼_ì „ë¬¸ì˜_ì—°ë ¹ì§€ì—­ì§„ë£Œê³¼/models/SVR_model.pkl
âœ… KNN ëª¨ë¸ ì €ì¥: model_results_ì§„ë£Œê³¼_ì „ë¬¸ì˜_ì—°ë ¹ì§€ì—­ì§„ë£Œê³¼/models/KNN_model.pkl

============================================================
ğŸ‰ ê°œì„ ëœ ëª¨ë¸ë§ ì™„ë£Œ!
============================================================
ğŸ“ ê²°ê³¼ íŒŒì¼ ìœ„ì¹˜: model_results_ì§„ë£Œê³¼_ì „ë¬¸ì˜_ì—°ë ¹ì§€ì—­ì§„ë£Œê³¼/
ğŸ“Š ì„±ëŠ¥ ë¹„êµ: performance/model_performance_comparison.csv
ğŸ¯ ì˜ˆì¸¡ ê²°ê³¼: predictions/
ğŸ’¾ ëª¨ë¸ íŒŒì¼: models/

ğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: ElasticNet
   - CV RÂ²: 0.9998 Â± 0.0003
   - CV RMSE: 0.0594 Â± 0.0982
   - CV MAE: 0.0226 Â± 0.0318

ğŸ¯ ì•™ìƒë¸” ëª¨ë¸ ì„±ëŠ¥:
   - Test RÂ²: 0.9863
   - Test RMSE: 0.3041
============================================================

'''
